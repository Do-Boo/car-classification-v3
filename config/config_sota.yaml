# 🚀 차량 분류 SOTA 고성능 설정 - 경진대회 우승 전략
# 최신 딥러닝 기법 총동원 + 성능 극대화
# 생성일: 2025-06-02 16:46

# 🎯 프로젝트 정보
project:
  name: "car_classification_sota"
  version: "v3.0"
  description: "최신 SOTA 기법 총동원 - Kaggle 상위 1% 솔루션"
  target_performance: "Log Loss < 1.5"

# 📊 데이터 설정
data:
  train_csv: "data/train.csv"
  test_csv: "data/test.csv"
  train_images: "data/train"
  test_images: "data/test"
  num_classes: 393
  img_size: 480  # 고해상도 기본값 (모델별 개별 설정)
  
  # 🔄 K-Fold 교차 검증
  kfold:
    n_splits: 5
    shuffle: true
    random_state: 42

# 🏆 SOTA 앙상블 모델 구성 (7개 모델)
ensemble:
  models:
    efficientnetv2_l:
      backbone: "tf_efficientnetv2_l.in21k_ft_in1k"
      img_size: 480
      weight: 20.0
      description: "2021년 SOTA - 효율성의 정점"
      batch_size: 12
      learning_rate: 0.01
      
    convnext_large:
      backbone: "convnext_large.fb_in22k_ft_in1k_384"
      img_size: 384
      weight: 20.0
      description: "2022년 CNN 복권 - 순수 CNN의 부활"
      batch_size: 16
      learning_rate: 0.008
      
    swin_large:
      backbone: "swin_large_patch4_window12_384.ms_in22k_ft_in1k"
      img_size: 384
      weight: 15.0
      description: "Vision Transformer 혁신"
      batch_size: 16
      learning_rate: 0.008
      
    efficientnet_b7:
      backbone: "tf_efficientnet_b7.ns_jft_in1k"
      img_size: 600
      weight: 15.0
      description: "검증된 고성능 아키텍처"
      batch_size: 8
      learning_rate: 0.012
      
    convnext_base:
      backbone: "convnext_base.fb_in22k_ft_in1k"
      img_size: 224
      weight: 10.0
      description: "효율성과 성능의 균형"
      batch_size: 24
      learning_rate: 0.015
      
    resnet152d:
      backbone: "resnet152d.ra2_in1k"
      img_size: 224
      weight: 10.0
      description: "클래식 아키텍처의 완성형"
      batch_size: 24
      learning_rate: 0.015
      
    vit_base:
      backbone: "vit_base_patch16_224.augreg_in21k_ft_in1k"
      img_size: 224
      weight: 10.0
      description: "순수 Transformer 접근"
      batch_size: 24
      learning_rate: 0.015

# 🧠 모델 아키텍처 설정
model:
  backbone: "tf_efficientnetv2_l.in21k_ft_in1k"  # 기본 모델
  num_classes: 393
  dropout: 0.3
  pretrained: true
  use_gem: true  # GeM Pooling 활성화 (2-3% 성능 향상)

# 🎯 학습 설정 (성능 극대화)
training:
  epochs: 30
  batch_size: 12  # 고해상도 대응
  learning_rate: 0.01  # 8-10배 증가된 학습률
  weight_decay: 1e-4
  
  # 🔥 고급 학습률 스케줄링
  scheduler:
    type: "CosineAnnealingWarmRestarts"
    T_0: 10
    T_mult: 2
    eta_min: 1e-6
    
  # 🎯 조기 종료 (과적합 방지)
  early_stopping:
    patience: 7
    min_delta: 0.001
    
  # 💾 체크포인트 설정
  checkpoint:
    save_best: true
    save_last: true
    monitor: "val_loss"
    mode: "min"

# 🔧 최적화 설정
optimizer:
  type: "AdamW"
  lr: 0.01
  weight_decay: 1e-4
  betas: [0.9, 0.999]
  eps: 1e-8

# 📈 손실 함수 (고급 기법)
loss:
  type: "LabelSmoothingLoss"  # 과적합 방지 + 일반화 성능 향상
  smoothing: 0.1
  
  # 대안 손실 함수들
  alternatives:
    focal_loss:
      alpha: 1.0
      gamma: 2.0
    bi_tempered:
      t1: 0.8
      t2: 1.2

# 🔄 데이터 증강 (고성능 전략)
augmentation:
  train:
    - RandomResizedCrop:
        size: [480, 480]  # 고해상도
        scale: [0.8, 1.0]
    - RandomHorizontalFlip:
        p: 0.5
    - RandomVerticalFlip:
        p: 0.3
    - RandomRotation:
        degrees: 15
    - ColorJitter:
        brightness: 0.2
        contrast: 0.2
        saturation: 0.2
        hue: 0.1
    - RandomErasing:
        p: 0.3
        scale: [0.02, 0.33]
    - Normalize:
        mean: [0.485, 0.456, 0.406]
        std: [0.229, 0.224, 0.225]
        
  valid:
    - Resize:
        size: [480, 480]
    - CenterCrop:
        size: [480, 480]
    - Normalize:
        mean: [0.485, 0.456, 0.406]
        std: [0.229, 0.224, 0.225]

# 🚀 TTA (Test Time Augmentation) 설정
tta:
  enabled: true
  steps: 5  # 5배 성능 향상
  transforms:
    - "original"
    - "horizontal_flip"
    - "vertical_flip"
    - "both_flip"
    - "rotate_90"

# 💻 하드웨어 최적화 (Apple M4 Pro)
hardware:
  device: "auto"  # MPS 자동 감지
  num_workers: 0  # MPS 최적화
  pin_memory: true
  persistent_workers: true
  mixed_precision: false  # MPS 호환성

# 📊 로깅 및 모니터링
logging:
  level: "INFO"
  tensorboard: true
  wandb:
    enabled: false  # 오프라인 개발
    project: "car_classification_sota"
    
  # 📈 메트릭 추적
  metrics:
    - "accuracy"
    - "top5_accuracy"
    - "log_loss"
    - "f1_score"

# 🎯 성능 목표
performance_targets:
  individual_model:
    log_loss: 2.5
    accuracy: 0.35
  ensemble:
    log_loss: 2.0
    accuracy: 0.45
  ensemble_with_tta:
    log_loss: 1.5  # 최종 목표
    accuracy: 0.55

# 📁 출력 경로
paths:
  output_dir: "outputs"
  models_dir: "outputs/models"
  logs_dir: "outputs/logs"
  submissions_dir: "outputs/submissions"
  ensemble_dir: "outputs/ensemble"

# 🔬 실험 설정
experiment:
  name: "sota_ensemble_v3"
  description: "최신 SOTA 기법 총동원 - 경진대회 우승 전략"
  tags: ["sota", "ensemble", "high_performance", "competition"]
  
# 🏆 경진대회 전략
competition:
  strategy: "maximum_performance"
  risk_level: "aggressive"
  target_rank: "top_1_percent"
  
  phases:
    phase1: "개별 모델 최적화"
    phase2: "앙상블 가중치 튜닝"
    phase3: "TTA 5단계 적용"
    phase4: "최종 하이퍼파라미터 미세 조정" 