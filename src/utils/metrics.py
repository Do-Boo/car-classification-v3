"""
í‰ê°€ ë©”íŠ¸ë¦­ í•¨ìˆ˜ë“¤
"""

import numpy as np
from sklearn.metrics import accuracy_score, log_loss, top_k_accuracy_score

def compute_metrics(y_true, y_pred_probs, num_classes=393):
    """
    ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­ ê³„ì‚°
    
    Args:
        y_true: ì‹¤ì œ ë ˆì´ë¸” (N,)
        y_pred_probs: ì˜ˆì¸¡ í™•ë¥  (N, num_classes)
        num_classes: ì „ì²´ í´ëž˜ìŠ¤ ìˆ˜
        
    Returns:
        dict: ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
    """
    # ðŸ”§ ë ˆì´ë¸”ì´ 1-basedì¸ ê²½ìš° 0-basedë¡œ ë³€í™˜
    if y_true.min() > 0:
        print(f"âš ï¸ ë ˆì´ë¸”ì´ 1-basedìž…ë‹ˆë‹¤. 0-basedë¡œ ë³€í™˜í•©ë‹ˆë‹¤. (min: {y_true.min()}, max: {y_true.max()})")
        y_true = y_true - 1  # 1-based â†’ 0-based ë³€í™˜
    
    # ì˜ˆì¸¡ í´ëž˜ìŠ¤
    y_pred = np.argmax(y_pred_probs, axis=1)
    
    # ì „ì²´ í´ëž˜ìŠ¤ ë ˆì´ë¸” ìƒì„± (0ë¶€í„° num_classes-1ê¹Œì§€)
    all_labels = list(range(num_classes))
    
    # ðŸ”§ ê²€ì¦ ë°ì´í„°ì— ëˆ„ë½ëœ í´ëž˜ìŠ¤ ì²˜ë¦¬
    unique_true_labels = np.unique(y_true)
    print(f"ðŸ“Š ê²€ì¦ ë°ì´í„° í´ëž˜ìŠ¤ ìˆ˜: {len(unique_true_labels)}/{num_classes}")
    print(f"ðŸ“Š ê²€ì¦ ë°ì´í„° í´ëž˜ìŠ¤ ë²”ìœ„: {unique_true_labels.min()}-{unique_true_labels.max()}")
    
    # ðŸ”§ ì•ˆì „í•œ log_loss ê³„ì‚°
    try:
        # ë°©ë²• 1: ì „ì²´ í´ëž˜ìŠ¤ ë ˆì´ë¸” ëª…ì‹œ
        computed_log_loss = log_loss(y_true, y_pred_probs, labels=all_labels)
        print(f"âœ… Log Loss ê³„ì‚° ì„±ê³µ (ë°©ë²• 1): {computed_log_loss:.6f}")
    except Exception as e:
        print(f"âš ï¸ ë°©ë²• 1 ì‹¤íŒ¨: {e}")
        try:
            # ë°©ë²• 2: ê²€ì¦ ë°ì´í„°ì— ìžˆëŠ” í´ëž˜ìŠ¤ë§Œ ì‚¬ìš©
            # ëˆ„ë½ëœ í´ëž˜ìŠ¤ì˜ í™•ë¥ ì„ 0ìœ¼ë¡œ ì„¤ì •í•˜ê³  ì •ê·œí™”
            y_pred_probs_safe = y_pred_probs.copy()
            
            # ê° ìƒ˜í”Œì˜ í™•ë¥  í•©ì´ 1ì´ ë˜ë„ë¡ ì •ê·œí™”
            row_sums = y_pred_probs_safe.sum(axis=1, keepdims=True)
            y_pred_probs_safe = y_pred_probs_safe / row_sums
            
            # ë§¤ìš° ìž‘ì€ ê°’ìœ¼ë¡œ í´ë¦¬í•‘ (log(0) ë°©ì§€)
            y_pred_probs_safe = np.clip(y_pred_probs_safe, 1e-15, 1 - 1e-15)
            
            # ê²€ì¦ ë°ì´í„°ì— ìžˆëŠ” í´ëž˜ìŠ¤ë§Œìœ¼ë¡œ log_loss ê³„ì‚°
            computed_log_loss = log_loss(y_true, y_pred_probs_safe, labels=all_labels)
            print(f"âœ… Log Loss ê³„ì‚° ì„±ê³µ (ë°©ë²• 2): {computed_log_loss:.6f}")
        except Exception as e2:
            print(f"âš ï¸ ë°©ë²• 2ë„ ì‹¤íŒ¨: {e2}")
            # ë°©ë²• 3: ìˆ˜ë™ ê³„ì‚°
            y_pred_probs_clipped = np.clip(y_pred_probs, 1e-15, 1 - 1e-15)
            log_probs = np.log(y_pred_probs_clipped)
            computed_log_loss = -np.mean([log_probs[i, y_true[i]] for i in range(len(y_true))])
            print(f"âœ… Log Loss ê³„ì‚° ì„±ê³µ (ë°©ë²• 3 - ìˆ˜ë™): {computed_log_loss:.6f}")
    
    # ë©”íŠ¸ë¦­ ê³„ì‚°
    metrics = {
        'accuracy': accuracy_score(y_true, y_pred) * 100,
        'log_loss': computed_log_loss,
        'top3_accuracy': top_k_accuracy_score(y_true, y_pred_probs, k=3) * 100,
        'top5_accuracy': top_k_accuracy_score(y_true, y_pred_probs, k=5) * 100,
    }
    
    return metrics

def calculate_class_weights(labels, num_classes):
    """
    í´ëž˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° (ë¶ˆê· í˜• ë°ì´í„° ëŒ€ì‘)
    
    Args:
        labels: ë ˆì´ë¸” ë°°ì—´
        num_classes: ì „ì²´ í´ëž˜ìŠ¤ ìˆ˜
        
    Returns:
        numpy array: í´ëž˜ìŠ¤ë³„ ê°€ì¤‘ì¹˜
    """
    # í´ëž˜ìŠ¤ë³„ ë¹ˆë„ ê³„ì‚°
    class_counts = np.bincount(labels, minlength=num_classes)
    
    # 0ì¸ í´ëž˜ìŠ¤ ì²˜ë¦¬
    class_counts[class_counts == 0] = 1
    
    # ê°€ì¤‘ì¹˜ ê³„ì‚° (inverse frequency)
    total_samples = len(labels)
    class_weights = total_samples / (num_classes * class_counts)
    
    # ì •ê·œí™”
    class_weights = class_weights / class_weights.mean()
    
    return class_weights

def multiclass_log_loss_with_mapping(answer_df, submission_df, class_mapping=None):
    """
    ëŒ€íšŒ í‰ê°€ í•¨ìˆ˜ (í´ëž˜ìŠ¤ ë§¤í•‘ í¬í•¨)
    
    Args:
        answer_df: ì •ë‹µ DataFrame (ID, label)
        submission_df: ì œì¶œ DataFrame (ID, ê° í´ëž˜ìŠ¤ë³„ í™•ë¥ )
        class_mapping: ë™ì¼ í´ëž˜ìŠ¤ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬
        
    Returns:
        float: Log Loss
    """
    # í´ëž˜ìŠ¤ ë¦¬ìŠ¤íŠ¸
    class_list = sorted(answer_df['label'].unique())
    
    # ë§¤í•‘ ì ìš©
    if class_mapping:
        # ì •ë‹µ ë ˆì´ë¸” ë§¤í•‘
        answer_df = answer_df.copy()
        answer_df['label'] = answer_df['label'].map(lambda x: class_mapping.get(x, x))
        
        # ì œì¶œ DataFrame ì»¬ëŸ¼ ë§¤í•‘
        submission_df = submission_df.copy()
        for old_class, new_class in class_mapping.items():
            if old_class in submission_df.columns and new_class in submission_df.columns:
                # ë‘ í´ëž˜ìŠ¤ì˜ í™•ë¥ ì„ í•©ì‚°
                submission_df[new_class] = submission_df[new_class] + submission_df[old_class]
                submission_df = submission_df.drop(columns=[old_class])
        
        # í´ëž˜ìŠ¤ ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
        class_list = sorted(answer_df['label'].unique())
    
    # ê²€ì¦
    if submission_df.shape[0] != answer_df.shape[0]:
        raise ValueError("submission_df í–‰ ê°œìˆ˜ê°€ answer_dfì™€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    # ID ì •ë ¬
    submission_df = submission_df.sort_values(by='ID').reset_index(drop=True)
    answer_df = answer_df.sort_values(by='ID').reset_index(drop=True)
    
    if not all(answer_df['ID'] == submission_df['ID']):
        raise ValueError("IDê°€ ì •ë ¬ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë¶ˆì¼ì¹˜í•©ë‹ˆë‹¤.")
    
    # ëˆ„ë½ëœ í´ëž˜ìŠ¤ í™•ì¸
    missing_cols = [col for col in class_list if col not in submission_df.columns]
    if missing_cols:
        raise ValueError(f"í´ëž˜ìŠ¤ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}")
    
    # NaN í™•ì¸
    if submission_df[class_list].isnull().any().any():
        raise ValueError("NaN í¬í•¨ë¨")
    
    # í™•ë¥  ë²”ìœ„ í™•ì¸
    for col in class_list:
        if not ((submission_df[col] >= 0) & (submission_df[col] <= 1)).all():
            raise ValueError(f"{col}ì˜ í™•ë¥ ê°’ì´ 0~1 ë²”ìœ„ ì´ˆê³¼")
    
    # ì •ë‹µ ì¸ë±ìŠ¤ ë³€í™˜
    true_labels = answer_df['label'].tolist()
    true_idx = [class_list.index(lbl) for lbl in true_labels]
    
    # í™•ë¥  ì •ê·œí™” + clip
    probs = submission_df[class_list].values
    probs = probs / probs.sum(axis=1, keepdims=True)
    y_pred = np.clip(probs, 1e-15, 1 - 1e-15)
    
    return log_loss(true_idx, y_pred, labels=list(range(len(class_list))))
