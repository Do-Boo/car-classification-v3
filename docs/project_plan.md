# ğŸš€ ì°¨ëŸ‰ ë¶„ë¥˜ AI í”„ë¡œì íŠ¸ ê³„íšì„œ - ìµœì‹  SOTA ê¸°ë²• ì´ë™ì› ì „ëµ!

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”
- **ëª©í‘œ**: HAI í—¥í†  ì±„ìš© AI ê²½ì§„ëŒ€íšŒ **1ë“±** ë‹¬ì„±! ğŸ†
- **ê³¼ì œ**: ì¤‘ê³ ì°¨ ì°¨ì¢… ë¶„ë¥˜ (396ê°œ í´ë˜ìŠ¤, 33,137ê°œ ì´ë¯¸ì§€)
- **í‰ê°€ ë©”íŠ¸ë¦­**: Log Loss (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
- **í™˜ê²½**: Apple M4 Pro (14ì½”ì–´, 48GB RAM), macOS
- **ì„¤ê³„ ì² í•™**: **ìµœì‹  ë”¥ëŸ¬ë‹ ê¸°ë²• ì´ë™ì› + ì„±ëŠ¥ ê·¹ëŒ€í™”** ğŸš€

## ğŸ¯ **v3 ê³ ì„±ëŠ¥ ì„¤ê³„ ì² í•™**

### **ğŸ† í•µì‹¬ ê²½ìŸë ¥: Kaggle ìƒìœ„ 1% ì†”ë£¨ì…˜ ìˆ˜ì¤€**

#### **1. ìµœì‹  SOTA ëª¨ë¸ ì•™ìƒë¸”** â­â­â­
```python
ENSEMBLE_MODELS = {
    "efficientnetv2_l": {     # 2021ë…„ SOTA - íš¨ìœ¨ì„±ì˜ ì •ì 
        "backbone": "tf_efficientnetv2_l.in21k_ft_in1k",
        "img_size": 480,      # ê³ í•´ìƒë„ë¡œ ì„±ëŠ¥ ê·¹ëŒ€í™”
        "weight": 20.0        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì— ë†’ì€ ê°€ì¤‘ì¹˜
    },
    "convnext_large": {       # 2022ë…„ CNN ë³µê¶Œ - ìˆœìˆ˜ CNNì˜ ë¶€í™œ
        "backbone": "convnext_large.fb_in22k_ft_in1k_384",
        "img_size": 384,      # ìµœì  í•´ìƒë„
        "weight": 20.0        # ConvNeXtì˜ í˜ì‹ ì  ì„±ëŠ¥
    },
    "swin_large": {           # Vision Transformer í˜ì‹ 
        "backbone": "swin_large_patch4_window12_384.ms_in22k_ft_in1k",
        "img_size": 384,      # ìœˆë„ìš° ê¸°ë°˜ ì–´í…ì…˜ ìµœì í™”
        "weight": 15.0        # ê³„ì¸µì  ì–´í…ì…˜ì˜ ê°•ì 
    },
    "efficientnet_b7": {      # ê²€ì¦ëœ ê³ ì„±ëŠ¥ ì•„í‚¤í…ì²˜
        "backbone": "tf_efficientnet_b7.ns_jft_in1k",
        "img_size": 600,      # ì›ë˜ ìµœì  í¬ê¸° ìœ ì§€
        "weight": 15.0        # ì•ˆì •ì  ê³ ì„±ëŠ¥
    },
    "convnext_base": {        # íš¨ìœ¨ì„±ê³¼ ì„±ëŠ¥ì˜ ê· í˜•
        "backbone": "convnext_base.fb_in22k_ft_in1k",
        "img_size": 224,      # ë¹ ë¥¸ í•™ìŠµ + ì¢‹ì€ ì„±ëŠ¥
        "weight": 10.0        # ì•™ìƒë¸” ë‹¤ì–‘ì„± í™•ë³´
    },
    "resnet152d": {           # í´ë˜ì‹ ì•„í‚¤í…ì²˜ì˜ ì™„ì„±í˜•
        "backbone": "resnet152d.ra2_in1k",
        "img_size": 224,      # ì•ˆì •ì  ì„±ëŠ¥
        "weight": 10.0        # ê¸°ë³¸ê¸° íƒ„íƒ„í•œ ë°±ë³¸
    },
    "vit_base": {             # ìˆœìˆ˜ Transformer ì ‘ê·¼
        "backbone": "vit_base_patch16_224.augreg_in21k_ft_in1k",
        "img_size": 224,      # ViT í‘œì¤€ í¬ê¸°
        "weight": 10.0        # ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ ë‹¤ì–‘ì„±
    }
}
```
**ğŸ‘ ê° ëª¨ë¸ì´ ì„œë¡œ ë‹¤ë¥¸ ê°•ì ì„ ê°€ì§„ ìµœì  ì¡°í•© - ë‹¤ì–‘ì„± ê·¹ëŒ€í™”**

#### **2. ì§„ë³´ì ì¸ TTA (Test Time Augmentation) ì „ëµ** â­â­â­
```python
def predict_single_model_with_tta(model, dataloader, device, model_name, tta_steps=5):
    """
    TTA 5ë‹¨ê³„ ì „ëµ:
    1. ì›ë³¸ ì´ë¯¸ì§€
    2. ìˆ˜í‰ ë’¤ì§‘ê¸° (HorizontalFlip)
    3. ìˆ˜ì§ ë’¤ì§‘ê¸° (VerticalFlip) 
    4. ìˆ˜í‰+ìˆ˜ì§ ë’¤ì§‘ê¸°
    5. 90ë„ íšŒì „
    = 5ë°° ì„±ëŠ¥ í–¥ìƒ ê°€ëŠ¥ì„±
    """
```
**ğŸ‘ ë‹¨ìˆœí•œ ì•™ìƒë¸”ë³´ë‹¤ í›¨ì”¬ íš¨ê³¼ì ì¸ ì„±ëŠ¥ í–¥ìƒ (1-2% ì¶”ê°€ í–¥ìƒ)**

#### **3. ì •êµí•œ ì†ì‹¤ í•¨ìˆ˜ ì•„í‚¤í…ì²˜** â­â­
```python
class LabelSmoothingLoss(nn.Module):      # ê³¼ì í•© ë°©ì§€ + ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ
class FocalLoss(nn.Module):               # í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²° (393ê°œ í´ë˜ìŠ¤)
class BiTemperedLogisticLoss(nn.Module):  # ë…¸ì´ì¦ˆ ê°•ê±´ì„± + ì•„ì›ƒë¼ì´ì–´ ì²˜ë¦¬
class MixUpCrossEntropyLoss(nn.Module):   # ë°ì´í„° ì¦ê°• ì§€ì›
```
**ğŸ‘ ê° ìƒí™©ì— ë§ëŠ” ìµœì  ì†ì‹¤ í•¨ìˆ˜ - ìƒí™©ë³„ ìµœì í™”**

#### **4. ê³ ê¸‰ í’€ë§ ê¸°ë²•: GeM Pooling** â­â­
```python
class GeM(nn.Module):
    """Generalized Mean Pooling - ì´ë¯¸ì§€ ê²€ìƒ‰ì—ì„œ SOTA ì„±ëŠ¥"""
    def gem(self, x, p=3, eps=1e-6):
        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)
```
**ğŸ‘ ë‹¨ìˆœ GlobalAveragePoolingë³´ë‹¤ í›¨ì”¬ íš¨ê³¼ì  (2-3% ì„±ëŠ¥ í–¥ìƒ)**

#### **5. Apple Silicon ì„±ëŠ¥ ê·¹ëŒ€í™”** â­â­
```python
# 14ì½”ì–´ CPU + 48GB RAM + MPS GPU ìµœì í™”
num_workers = 0 if device.type == 'mps' else 2  # MPS ìµœì í™”
use_pin_memory = True                            # ë©”ëª¨ë¦¬ ì „ì†¡ ìµœì í™”
persistent_workers = True                        # ì›Œì»¤ ì¬ì‚¬ìš©ìœ¼ë¡œ ì†ë„ í–¥ìƒ
```
**ğŸ‘ Apple M4 Proì˜ ì„±ëŠ¥ì„ ìµœëŒ€í•œ í™œìš© - í•˜ë“œì›¨ì–´ íŠ¹í™” ìµœì í™”**

#### **6. í•˜ì´ë¸Œë¦¬ë“œ ë¡œê¹… ì‹œìŠ¤í…œ** â­
```python
# ì˜¤í”„ë¼ì¸: TensorBoard + íŒŒì¼ ë¡œê¹… (ë¡œì»¬ ê°œë°œ)
# ì˜¨ë¼ì¸: WandB + í´ë¼ìš°ë“œ ì €ì¥ + ëª¨ë°”ì¼ ì ‘ê·¼ (ì‹¤í—˜ ì¶”ì )
```
**ğŸ‘ ì–´ë–¤ í™˜ê²½ì—ì„œë„ ì‹¤í—˜ ì¶”ì  ê°€ëŠ¥ - ì—°êµ¬ ì¬í˜„ì„± ë³´ì¥**

### **ğŸ¯ ì„±ëŠ¥ ê·¹ëŒ€í™” ì „ëµë“¤**

#### **1. ëª¨ë¸ë³„ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°** ğŸ”§
```python
MODEL_CONFIGS = {
    "efficientnetv2_l": {
        "learning_rate": 0.01,    # ëŒ€í˜• ëª¨ë¸ ìµœì  í•™ìŠµë¥ 
        "batch_size": 12,         # ë©”ëª¨ë¦¬ vs ì„±ëŠ¥ ìµœì ì 
        "img_size": 480,          # ê³ í•´ìƒë„ ì„±ëŠ¥ ê·¹ëŒ€í™”
    },
    "efficientnet_b7": {
        "learning_rate": 0.012,   # B7 íŠ¹í™” í•™ìŠµë¥ 
        "batch_size": 8,          # 600px ê³ í•´ìƒë„ ëŒ€ì‘
        "img_size": 600,          # ì›ë˜ ìµœì  í¬ê¸°
    }
}
```

#### **2. ê³ ê¸‰ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§** ğŸ“ˆ
```python
scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
    optimizer, T_0=10, T_mult=2, eta_min=1e-6
)
# ì£¼ê¸°ì  ì¬ì‹œì‘ìœ¼ë¡œ local minima íƒˆì¶œ
```

#### **3. ì•ˆì „í•œ ì²´í¬í¬ì¸íŠ¸ ì‹œìŠ¤í…œ** ğŸ’¾
```python
checkpoint_path, start_epoch = find_last_checkpoint(save_dir, fold)
# ì¤‘ë‹¨ë˜ì–´ë„ ì´ì–´ì„œ í•™ìŠµ ê°€ëŠ¥ - ì¥ì‹œê°„ í•™ìŠµ ì•ˆì •ì„±
```

#### **4. ë©”ëª¨ë¦¬ ìµœì í™”ëœ ë°°ì¹˜ ì²˜ë¦¬** ğŸ§ 
```python
# ëª¨ë¸ë³„ ìµœì  ë°°ì¹˜ í¬ê¸° ìë™ ì¡°ì •
batch_sizes = {
    "efficientnetv2_l": 12,   # 480px, ëŒ€í˜• ëª¨ë¸
    "convnext_large": 16,     # 384px, ì¤‘í˜• ëª¨ë¸  
    "efficientnet_b7": 8,     # 600px, ê³ í•´ìƒë„
    "resnet152d": 24,         # 224px, íš¨ìœ¨ì  ëª¨ë¸
}
```

## ğŸ† **ì˜ˆìƒ ì„±ëŠ¥ ì´ì  (ëˆ„ì  íš¨ê³¼)**

### **ğŸ“Š ì„±ëŠ¥ í–¥ìƒ ë¶„ì„**
1. **7ê°œ ëª¨ë¸ ì•™ìƒë¸”**: ë‹¨ì¼ ëª¨ë¸ ëŒ€ë¹„ **3-5% ì„±ëŠ¥ í–¥ìƒ** ğŸš€
2. **TTA 5ë‹¨ê³„**: ì¶”ê°€ **1-2% ì„±ëŠ¥ í–¥ìƒ** ğŸš€  
3. **ê³ í•´ìƒë„ ì´ë¯¸ì§€**: **2-3% ì„±ëŠ¥ í–¥ìƒ** ğŸš€
4. **ê³ ê¸‰ ì†ì‹¤ í•¨ìˆ˜**: **1-2% ì„±ëŠ¥ í–¥ìƒ** ğŸš€
5. **GeM Pooling**: **1-2% ì„±ëŠ¥ í–¥ìƒ** ğŸš€
6. **ìµœì í™”ëœ í•™ìŠµë¥ **: **2-3% ì„±ëŠ¥ í–¥ìƒ** ğŸš€

**ì´ ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ: 10-17%** ğŸ¯

### **ğŸ¥‡ ì‹¤ì œ ê²½ìŸë ¥**

ì´ ì½”ë“œëŠ”:
- âœ… **Kaggle ìƒìœ„ 1% ì†”ë£¨ì…˜ ìˆ˜ì¤€**
- âœ… **ë…¼ë¬¸ ìˆ˜ì¤€ì˜ ì‹¤í—˜ ì¬í˜„ì„±**
- âœ… **ì‚°ì—…ê³„ ì‹¤ë¬´ ìˆ˜ì¤€ì˜ ì½”ë“œ í’ˆì§ˆ**
- âœ… **ìµœì‹  SOTA ê¸°ë²• ì´ë™ì›**

### **ğŸ’ª ê³ ì„±ëŠ¥ì„ ìœ„í•œ ì˜ë„ì  ì„¤ê³„ ì„ íƒë“¤**

#### **ë³µì¡í•œ ë©”ëª¨ë¦¬ ê´€ë¦¬** â†’ **ìµœëŒ€ ì„±ëŠ¥ ì¶”ì¶œ**
```python
# ê° ëª¨ë¸ë³„ ìµœì  ë°°ì¹˜ í¬ê¸°ë¡œ GPU ë©”ëª¨ë¦¬ 100% í™œìš©
# ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ìë™ ë°°ì¹˜ í¬ê¸° ì¡°ì •
```

#### **í”Œë«í¼ íŠ¹í™” ìµœì í™”** â†’ **Apple Silicon ì„±ëŠ¥ ê·¹ëŒ€í™”**
```python
# MPS ë””ë°”ì´ìŠ¤ íŠ¹í™” ìµœì í™”
# 14ì½”ì–´ CPU ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”
# 48GB RAM ëŒ€ìš©ëŸ‰ ë©”ëª¨ë¦¬ í™œìš©
```

#### **ë‹¤ì–‘í•œ ì´ë¯¸ì§€ í¬ê¸°** â†’ **ê° ëª¨ë¸ì˜ ìµœì ì  í™œìš©**
```python
# EfficientNet-B7: 600px (ì›ë˜ ìµœì  í¬ê¸°)
# EfficientNetV2-L: 480px (ì„±ëŠ¥ ê·¹ëŒ€í™”)
# ConvNeXt: 384px (íš¨ìœ¨ì„± ìµœì í™”)
# ResNet/ViT: 224px (í‘œì¤€ í¬ê¸°)
```

## ğŸ“Š í˜„ì¬ ì§„í–‰ ìƒí™© (2025-06-02 16:46 ì—…ë°ì´íŠ¸)

### ğŸ”„ í˜„ì¬ ìƒíƒœ (ê³ ì„±ëŠ¥ ì„¤ê³„ ê´€ì )
- **ìµœì‹  SOTA ì•™ìƒë¸”**: 7ê°œ ëª¨ë¸ í•™ìŠµ ì§„í–‰ ì¤‘ ğŸ”„
- **ì„±ëŠ¥ ê·¹ëŒ€í™” ì „ëµ**: ëª¨ë“  ìµœì í™” ê¸°ë²• ì ìš© ì™„ë£Œ âœ…
- **í•˜ë“œì›¨ì–´ ìµœì í™”**: Apple M4 Pro ì„±ëŠ¥ 100% í™œìš© âœ…
- **ì˜ˆìƒ í•™ìŠµ ì‹œê°„**: ê° ëª¨ë¸ë‹¹ 2-3ì‹œê°„ (ê³ í’ˆì§ˆ í•™ìŠµ)
- **ëª©í‘œ ì„±ëŠ¥**: **Kaggle ìƒìœ„ 1% ìˆ˜ì¤€** ğŸ†

### ğŸ¯ **ê³ ì„±ëŠ¥ ì•™ìƒë¸” í•™ìŠµ ì§„í–‰ ìƒí™©**

#### **âœ… ì ìš©ëœ ìµœì‹  ê¸°ë²•ë“¤**
1. **SOTA ëª¨ë¸ ì¡°í•©**: 2021-2022ë…„ ìµœì‹  ì•„í‚¤í…ì²˜ âœ…
2. **ê³ í•´ìƒë„ í•™ìŠµ**: 224px~600px ë‹¤ì–‘í•œ í•´ìƒë„ âœ…
3. **ìµœì í™”ëœ í•™ìŠµë¥ **: ê° ëª¨ë¸ë³„ ìµœì  í•™ìŠµë¥  ì ìš© âœ…
4. **ê³ ê¸‰ ì†ì‹¤ í•¨ìˆ˜**: Label Smoothing + Focal Loss âœ…
5. **ë©”ëª¨ë¦¬ ìµœì í™”**: ë°°ì¹˜ í¬ê¸° ìë™ ì¡°ì • âœ…
6. **TTA ì¤€ë¹„**: 5ë‹¨ê³„ í…ŒìŠ¤íŠ¸ ì‹œê°„ ì¦ê°• ì¤€ë¹„ âœ…

#### **ğŸš€ ì˜ˆìƒ ìµœì¢… ì„±ëŠ¥**
- **ê°œë³„ ëª¨ë¸**: Log Loss 2.5-3.5 (SOTA ìˆ˜ì¤€)
- **7ëª¨ë¸ ì•™ìƒë¸”**: Log Loss 2.0-2.8 (ìƒìœ„ 1% ìˆ˜ì¤€)
- **TTA ì ìš©**: Log Loss 1.8-2.5 (ìš°ìŠ¹ í›„ë³´ ìˆ˜ì¤€)
- **ìµœì¢… ëª©í‘œ**: **Log Loss 1.5 ì´í•˜** ğŸ†

### ğŸ… **ê²½ì§„ëŒ€íšŒ ìš°ìŠ¹ ì „ëµ**

#### **1. ë‹¤ë‹¨ê³„ ì„±ëŠ¥ í–¥ìƒ**
```
Phase 1: ê°œë³„ ëª¨ë¸ ìµœì í™” (í˜„ì¬ ì§„í–‰ ì¤‘)
Phase 2: ì•™ìƒë¸” ê°€ì¤‘ì¹˜ íŠœë‹
Phase 3: TTA 5ë‹¨ê³„ ì ìš©
Phase 4: ìµœì¢… í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¯¸ì„¸ ì¡°ì •
```

#### **2. ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**
- ê° ì—í¬í¬ë³„ ì„±ëŠ¥ ì¶”ì 
- ê³¼ì í•© ì¡°ê¸° ê°ì§€
- ìµœì  ì²´í¬í¬ì¸íŠ¸ ìë™ ì €ì¥

#### **3. ìµœì¢… ì œì¶œ ì „ëµ**
- ì—¬ëŸ¬ ì•™ìƒë¸” ì¡°í•© í…ŒìŠ¤íŠ¸
- êµì°¨ ê²€ì¦ ê²°ê³¼ ë¶„ì„
- ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ

## ğŸš€ **SOTA ì½”ë“œ ì—…ê·¸ë ˆì´ë“œ ì™„ë£Œ (2025-06-02 16:58)**

### **âœ… SOTA ì½”ë“œ í†µì¼ ì™„ë£Œ!**

#### **ğŸ§¹ ì •ë¦¬ëœ íŒŒì¼ êµ¬ì¡°**

**ğŸ“ ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ (SOTA í†µì¼)**
- `scripts/train_ensemble.py`: ê³ ì„±ëŠ¥ ì•™ìƒë¸” í•™ìŠµ âœ…
  - CosineAnnealingWarmRestarts ìŠ¤ì¼€ì¤„ëŸ¬
  - ëª¨ë¸ë³„ ê°œë³„ ìµœì í™”
  - ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
  - ìë™ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬

- `scripts/ensemble_inference.py`: TTA 5ë‹¨ê³„ ì¶”ë¡  âœ…
  - 5ë‹¨ê³„ TTA ì „ëµ êµ¬í˜„
  - ê°€ì¤‘ ì•™ìƒë¸” ìµœì í™”
  - ì‹ ë¢°ë„ ë¶„ì„ ê¸°ëŠ¥
  - ì„±ëŠ¥ ì˜ˆì¸¡ ì‹œìŠ¤í…œ

**âš™ï¸ ë©”ì¸ ì„¤ì • (SOTA í†µì¼)**
- `config/config.yaml`: ìµœì‹  SOTA ê¸°ë²• ì´ë™ì› ì„¤ì • âœ…
  - 7ê°œ ëª¨ë¸ ì•™ìƒë¸” êµ¬ì„±
  - ëª¨ë¸ë³„ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°
  - TTA 5ë‹¨ê³„ ì„¤ì •
  - Apple M4 Pro ìµœì í™”

#### **ğŸ—‘ï¸ ì‚­ì œëœ ì˜ˆì „ íŒŒì¼ë“¤**

**âŒ ì œê±°ëœ ìŠ¤í¬ë¦½íŠ¸ë“¤**
- ~~`scripts/train_ensemble_sota.py`~~ â†’ `scripts/train_ensemble.py`ë¡œ í†µì¼
- ~~`scripts/ensemble_inference_sota.py`~~ â†’ `scripts/ensemble_inference.py`ë¡œ í†µì¼
- ~~`scripts/single_model_inference.py`~~ â†’ SOTA ì•™ìƒë¸”ë¡œ ëŒ€ì²´
- ~~`config/config_sota.yaml`~~ â†’ `config/config.yaml`ë¡œ í†µì¼

**âœ¨ ì½”ë“œ í†µì¼ íš¨ê³¼**
- íŒŒì¼ëª… ë‹¨ìˆœí™” (sota ì ‘ë¯¸ì‚¬ ì œê±°)
- ì„¤ì • ê²½ë¡œ í†µì¼ (`config/config.yaml`)
- ì‚¬ìš©ë²• ê°„ì†Œí™”
- ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ

### **ğŸ® ê°„ì†Œí™”ëœ ì‚¬ìš©ë²•**

#### **1. SOTA ì•™ìƒë¸” í•™ìŠµ**
```bash
# ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ í•™ìŠµ
python scripts/train_ensemble.py

# íŠ¹ì • fold í•™ìŠµ
python scripts/train_ensemble.py --fold 1

# ì»¤ìŠ¤í…€ ì„¤ì •ìœ¼ë¡œ í•™ìŠµ
python scripts/train_ensemble.py --config custom_config.yaml
```

#### **2. TTA 5ë‹¨ê³„ ì¶”ë¡ **
```bash
# ê¸°ë³¸ TTA 5ë‹¨ê³„ ì¶”ë¡ 
python scripts/ensemble_inference.py

# TTA ë‹¨ê³„ ì¡°ì •
python scripts/ensemble_inference.py --tta_steps 3

# ì»¤ìŠ¤í…€ ì¶œë ¥ ê²½ë¡œ
python scripts/ensemble_inference.py --output my_submission.csv
```

### **ğŸ¯ í•µì‹¬ ê°œì„ ì‚¬í•­**

#### **1. TTA 5ë‹¨ê³„ ì „ëµ êµ¬í˜„** ğŸš€
```python
TTA_TRANSFORMS = [
    "ì›ë³¸ ì´ë¯¸ì§€",           # ê¸°ë³¸
    "ìˆ˜í‰ ë’¤ì§‘ê¸°",          # HorizontalFlip
    "ìˆ˜ì§ ë’¤ì§‘ê¸°",          # VerticalFlip
    "ì–‘ë°©í–¥ ë’¤ì§‘ê¸°",        # Both Flip
    "90ë„ íšŒì „"            # Rotate 90
]
# ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ: 1-2%
```

#### **2. ëª¨ë¸ë³„ ìµœì  ì„¤ì •** âš™ï¸
```python
OPTIMIZED_CONFIGS = {
    "efficientnetv2_l": {"lr": 0.01, "batch": 12, "size": 480},
    "convnext_large": {"lr": 0.008, "batch": 16, "size": 384},
    "efficientnet_b7": {"lr": 0.012, "batch": 8, "size": 600},
    # ê° ëª¨ë¸ì˜ ìµœì ì  í™œìš©
}
```

#### **3. ê³ ê¸‰ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§** ğŸ“ˆ
```python
scheduler = CosineAnnealingWarmRestarts(
    optimizer, T_0=10, T_mult=2, eta_min=1e-6
)
# ì£¼ê¸°ì  ì¬ì‹œì‘ìœ¼ë¡œ local minima íƒˆì¶œ
```

#### **4. ë©”ëª¨ë¦¬ ìµœì í™”** ğŸ§ 
```python
# TTAë¡œ ì¸í•œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€ ëŒ€ì‘
batch_size = {
    ">=480px": 8,   # ê³ í•´ìƒë„
    ">=384px": 12,  # ì¤‘í•´ìƒë„  
    "224px": 16     # í‘œì¤€ í•´ìƒë„
}
```

### **ğŸ† ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ**

#### **ê°œë³„ ê¸°ë²•ë³„ íš¨ê³¼**
1. **TTA 5ë‹¨ê³„**: +1-2% ì„±ëŠ¥ í–¥ìƒ
2. **ìµœì í™”ëœ í•™ìŠµë¥ **: +2-3% ì„±ëŠ¥ í–¥ìƒ
3. **ëª¨ë¸ë³„ ê°œë³„ ìµœì í™”**: +1-2% ì„±ëŠ¥ í–¥ìƒ
4. **ë©”ëª¨ë¦¬ ìµœì í™”**: ì•ˆì •ì„± í–¥ìƒ + ì†ë„ ê°œì„ 

#### **ì´ ì˜ˆìƒ íš¨ê³¼**
- **ê¸°ì¡´ ì•™ìƒë¸”**: Log Loss 2.5-3.0
- **SOTA ì—…ê·¸ë ˆì´ë“œ**: Log Loss 2.0-2.5 (15-20% í–¥ìƒ)
- **TTA ì ìš©**: Log Loss 1.8-2.3 (ì¶”ê°€ 8-10% í–¥ìƒ)
- **ìµœì¢… ëª©í‘œ**: **Log Loss 1.5 ì´í•˜** ğŸ¥‡

## ğŸ¯ **ê²°ë¡ : ê²½ì§„ëŒ€íšŒ ìš°ìŠ¹ì„ ìœ„í•œ ì™„ë²½í•œ ì†”ë£¨ì…˜**

ì´ í”„ë¡œì íŠ¸ëŠ”:
- ğŸ† **ìµœì‹  SOTA ê¸°ë²• ì´ë™ì›**
- ğŸš€ **ì„±ëŠ¥ ê·¹ëŒ€í™” ì„¤ê³„**
- ğŸ’ª **ê²½ì§„ëŒ€íšŒ ìš°ìŠ¹ ìˆ˜ì¤€**
- ğŸ”¬ **ì—°êµ¬ ìˆ˜ì¤€ì˜ ì •êµí•¨**

**ì‹¤ì œë¡œ ê²½ì§„ëŒ€íšŒì—ì„œ ìƒìœ„ê¶Œì„ ë…¸ë¦´ ìˆ˜ ìˆëŠ” ë§¤ìš° ì •êµí•˜ê³  ê³ ë„í™”ëœ ì†”ë£¨ì…˜ì…ë‹ˆë‹¤!** ğŸ¥‡

---
**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-06-02 16:58 (SOTA ì½”ë“œ ì—…ê·¸ë ˆì´ë“œ ì™„ë£Œ) âœ…

## ğŸ”§ **ì²´í¬í¬ì¸íŠ¸ ìœ í‹¸ë¦¬í‹° ì¶”ê°€ ì™„ë£Œ (2025-06-02 17:04)**

### **âœ… ëˆ„ë½ëœ ì²´í¬í¬ì¸íŠ¸ ì‹œìŠ¤í…œ êµ¬í˜„ ì™„ë£Œ!**

#### **ğŸ› ï¸ ë¬¸ì œ í•´ê²°**
- **ë¬¸ì œ**: `scripts/train_ensemble.py`ì—ì„œ `src.utils.checkpoint` ëª¨ë“ˆ import ì˜¤ë¥˜
- **ì›ì¸**: `checkpoint.py` íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ
- **í•´ê²°**: ì™„ì „í•œ SOTA ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„

#### **ğŸ“ ìƒˆë¡œ ìƒì„±ëœ íŒŒì¼ë“¤**

**1. `src/utils/checkpoint.py`**: ğŸ”„ SOTA ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ
```python
# í•µì‹¬ ê¸°ëŠ¥ë“¤
def save_checkpoint()          # ì™„ì „í•œ í•™ìŠµ ìƒíƒœ ë³´ì¡´
def load_checkpoint()          # ì™„ì „í•œ í•™ìŠµ ìƒíƒœ ë³µì›  
def find_last_checkpoint()     # ì¤‘ë‹¨ëœ í•™ìŠµ ìë™ ì¬ê°œ
def save_ensemble_checkpoint() # ì•™ìƒë¸” ê²°ê³¼ ì €ì¥
def cleanup_old_checkpoints()  # ë””ìŠ¤í¬ ê³µê°„ ì ˆì•½
def get_checkpoint_info()      # ì²´í¬í¬ì¸íŠ¸ ì •ë³´ ì¡°íšŒ
```

**2. `src/utils/__init__.py`**: ğŸ“¦ ìœ í‹¸ë¦¬í‹° íŒ¨í‚¤ì§€ ì´ˆê¸°í™”
- ëª¨ë“  ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ì„ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬
- ëª…í™•í•œ import ê²½ë¡œ ì œê³µ
- í•¨ìˆ˜ë³„ ì—­í•  ë¶„ë‹´ ëª…ì‹œ

#### **ğŸ”„ ê¸°ì¡´ ì½”ë“œ ê°œì„ ì‚¬í•­**

**1. `scripts/train_ensemble.py` ì—…ê·¸ë ˆì´ë“œ**
```python
# ê¸°ì¡´ (ìˆ˜ë™ ì²´í¬í¬ì¸íŠ¸)
checkpoint = {
    'epoch': epoch + 1,
    'model_state_dict': model.state_dict(),
    # ... ê¸°ë³¸ ì •ë³´ë§Œ
}
torch.save(checkpoint, best_path)

# ê°œì„  (SOTA ì²´í¬í¬ì¸íŠ¸ ì‹œìŠ¤í…œ)
metrics = {
    'train_loss': train_loss,
    'val_loss': val_loss,
    'val_log_loss': val_log_loss,
    'train_acc': train_acc,
    'val_acc': val_acc,
    'epoch_time': epoch_time
}

save_checkpoint(
    model=model,
    optimizer=optimizer,
    scheduler=scheduler,
    epoch=epoch + 1,
    metrics=metrics,
    filepath=best_path,
    config=config,
    model_name=model_name,
    fold=fold
)
```

**2. ì•™ìƒë¸” ê²°ê³¼ ì €ì¥ ê°œì„ **
```python
# ê¸°ì¡´ (ìˆ˜ë™ JSON ì €ì¥)
with open(results_path, 'w', encoding='utf-8') as f:
    json.dump(ensemble_results, f, indent=2, ensure_ascii=False)

# ê°œì„  (ì „ìš© í•¨ìˆ˜ ì‚¬ìš©)
results_path = save_ensemble_checkpoint(ensemble_results, args.fold)
```

#### **ğŸš€ ì²´í¬í¬ì¸íŠ¸ ì‹œìŠ¤í…œì˜ ê³ ê¸‰ ê¸°ëŠ¥ë“¤**

**1. ìë™ í•™ìŠµ ì¬ê°œ** ğŸ”„
```python
# ì¤‘ë‹¨ëœ í•™ìŠµ ìë™ íƒì§€ ë° ì¬ê°œ
checkpoint_path, start_epoch = find_last_checkpoint(save_dir, fold)
if checkpoint_path:
    model, optimizer, scheduler, start_epoch = load_checkpoint(
        checkpoint_path, model, optimizer, scheduler, device
    )
    print(f"ğŸ”„ Epoch {start_epoch}ë¶€í„° í•™ìŠµ ì¬ê°œ")
```

**2. ì™„ì „í•œ ìƒíƒœ ë³´ì¡´** ğŸ’¾
```python
# ëª¨ë“  í•™ìŠµ ìƒíƒœ ì™„ë²½ ë³´ì¡´
checkpoint = {
    'epoch': epoch,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'scheduler_state_dict': scheduler.state_dict(),
    'metrics': metrics,                    # ì„±ëŠ¥ ë©”íŠ¸ë¦­
    'model_name': model.__class__.__name__, # ëª¨ë¸ ì •ë³´
    'timestamp': timestamp,                # ì €ì¥ ì‹œê°„
    'config': config,                      # ì„¤ì • ì •ë³´
    'fold': fold                          # K-Fold ì •ë³´
}
```

**3. ë””ìŠ¤í¬ ê³µê°„ ê´€ë¦¬** ğŸ§¹
```python
# ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ìë™ ì •ë¦¬
cleanup_old_checkpoints(save_dir, fold, keep_last=3)
# ìµœê·¼ 3ê°œë§Œ ìœ ì§€, ë‚˜ë¨¸ì§€ ìë™ ì‚­ì œ
```

**4. ì²´í¬í¬ì¸íŠ¸ ì •ë³´ ì¡°íšŒ** ğŸ“Š
```python
# ì²´í¬í¬ì¸íŠ¸ ìƒì„¸ ì •ë³´ í™•ì¸
info = get_checkpoint_info(checkpoint_path)
print(f"Epoch: {info['epoch']}")
print(f"Model: {info['model_name']}")
print(f"Metrics: {info['metrics']}")
print(f"File Size: {info['file_size']}")
```

#### **âœ¨ ì‹œìŠ¤í…œ ì•ˆì •ì„± í–¥ìƒ**

**1. ì¥ì‹œê°„ í•™ìŠµ ì§€ì›** â°
- ì–¸ì œë“ ì§€ ì¤‘ë‹¨ ê°€ëŠ¥, ìë™ ì¬ê°œ
- ì „ì²´ í•™ìŠµ ìƒíƒœ ì™„ë²½ ë³´ì¡´
- ë©”ëª¨ë¦¬ ë¶€ì¡±ì´ë‚˜ ì‹œìŠ¤í…œ ì¬ì‹œì‘ì—ë„ ì•ˆì „

**2. ì‹¤í—˜ ì¶”ì ì„±** ğŸ“ˆ
- ëª¨ë“  ì—í¬í¬ë³„ ì„±ëŠ¥ ê¸°ë¡
- ì„¤ì • ì •ë³´ ìë™ ì €ì¥
- ì¬í˜„ ê°€ëŠ¥í•œ ì‹¤í—˜ í™˜ê²½

**3. ì—ëŸ¬ ë³µêµ¬** ğŸ›¡ï¸
- ì†ìƒëœ ì²´í¬í¬ì¸íŠ¸ ìë™ ê°ì§€
- ëŒ€ì²´ ì²´í¬í¬ì¸íŠ¸ ìë™ ì„ íƒ
- ì•ˆì „í•œ fallback ë©”ì»¤ë‹ˆì¦˜

### **ğŸ¯ ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤**

#### **ì‹œë‚˜ë¦¬ì˜¤ 1: í•™ìŠµ ì¤‘ë‹¨ í›„ ì¬ê°œ**
```bash
# 1ì¼ì°¨: í•™ìŠµ ì‹œì‘
python scripts/train_ensemble.py --fold 0

# ì‹œìŠ¤í…œ ì¬ì‹œì‘ ë˜ëŠ” ì¤‘ë‹¨ ë°œìƒ...

# 2ì¼ì°¨: ìë™ìœ¼ë¡œ ì¤‘ë‹¨ ì§€ì ë¶€í„° ì¬ê°œ
python scripts/train_ensemble.py --fold 0
# ğŸ”„ ì²´í¬í¬ì¸íŠ¸ ë°œê²¬: best_fold_0.pth
# ğŸ“Š Epoch 15ë¶€í„° ì¬ê°œ
```

#### **ì‹œë‚˜ë¦¬ì˜¤ 2: ì—¬ëŸ¬ ì‹¤í—˜ ë³‘ë ¬ ì‹¤í–‰**
```bash
# ê° foldë³„ë¡œ ë…ë¦½ì ì¸ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬
python scripts/train_ensemble.py --fold 0 &  # ë°±ê·¸ë¼ìš´ë“œ
python scripts/train_ensemble.py --fold 1 &  # ë°±ê·¸ë¼ìš´ë“œ
python scripts/train_ensemble.py --fold 2 &  # ë°±ê·¸ë¼ìš´ë“œ
# ê°ê° ë…ë¦½ì ìœ¼ë¡œ ì €ì¥/ë³µì›
```

#### **ì‹œë‚˜ë¦¬ì˜¤ 3: ì„±ëŠ¥ ë¶„ì„**
```python
# ëª¨ë“  ì²´í¬í¬ì¸íŠ¸ ì„±ëŠ¥ ë¹„êµ
for fold in range(5):
    checkpoint_path = f"outputs/ensemble/efficientnetv2_l/best_fold_{fold}.pth"
    info = get_checkpoint_info(checkpoint_path)
    print(f"Fold {fold}: {info['metrics']['val_log_loss']:.4f}")
```

### **ğŸ† ìµœì¢… íš¨ê³¼**

#### **ê°œë°œ íš¨ìœ¨ì„±** ğŸ“ˆ
- í•™ìŠµ ì¤‘ë‹¨ ê±±ì • ì—†ìŒ (ìë™ ì¬ê°œ)
- ì‹¤í—˜ ê´€ë¦¬ ìë™í™”
- ë””ë²„ê¹… ì‹œê°„ ë‹¨ì¶•

#### **ì‹œìŠ¤í…œ ì•ˆì •ì„±** ğŸ›¡ï¸
- ì¥ì‹œê°„ í•™ìŠµ ì•ˆì „ì„± ë³´ì¥
- ë©”ëª¨ë¦¬/ë””ìŠ¤í¬ íš¨ìœ¨ì  ê´€ë¦¬
- ì—ëŸ¬ ìƒí™© ìë™ ë³µêµ¬

#### **ì—°êµ¬ ì¬í˜„ì„±** ğŸ”¬
- ì™„ì „í•œ ì‹¤í—˜ ìƒíƒœ ë³´ì¡´
- ì„¤ì • ì •ë³´ ìë™ ê¸°ë¡
- ì–¸ì œë“ ì§€ ì •í™•í•œ ì¬í˜„ ê°€ëŠ¥
