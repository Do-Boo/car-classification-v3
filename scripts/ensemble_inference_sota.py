#!/usr/bin/env python3
"""
ğŸš€ ì°¨ëŸ‰ ë¶„ë¥˜ SOTA ì•™ìƒë¸” ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ - TTA 5ë‹¨ê³„ ì „ëµ
ìµœì‹  ë”¥ëŸ¬ë‹ ê¸°ë²• ì´ë™ì› - ê²½ì§„ëŒ€íšŒ ìš°ìŠ¹ ì „ëµ!

ìƒì„±ì¼: 2025-06-02 16:46
ëª©í‘œ: Log Loss < 1.5, Kaggle ìƒìœ„ 1% ì†”ë£¨ì…˜
"""

import os
import sys
import yaml
import json
import argparse
import pandas as pd
import numpy as np
from pathlib import Path
import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

from src.models.backbone import get_model
from src.data.dataset import CarDataset, get_valid_transforms

def setup_device():
    """ë””ë°”ì´ìŠ¤ ì„¤ì • (Apple M4 Pro ìµœì í™”)"""
    if torch.backends.mps.is_available():
        device = torch.device("mps")
        print("ğŸš€ Apple M4 Pro MPS ê°€ì† í™œì„±í™”!")
    elif torch.cuda.is_available():
        device = torch.device("cuda")
        print("ğŸš€ CUDA GPU ê°€ì† í™œì„±í™”!")
    else:
        device = torch.device("cpu")
        print("ğŸ’» CPU ëª¨ë“œë¡œ ì‹¤í–‰")
    
    return device

def load_ensemble_models(ensemble_results_path, device):
    """SOTA ì•™ìƒë¸” ëª¨ë¸ë“¤ ë¡œë“œ"""
    with open(ensemble_results_path, 'r') as f:
        ensemble_results = json.load(f)
    
    models = {}
    
    print("ğŸ”„ SOTA ì•™ìƒë¸” ëª¨ë¸ ë¡œë“œ ì¤‘...")
    for model_name, info in ensemble_results.items():
        model_path = info['model_path']
        weight = info['weight']
        description = info.get('description', 'No description')
        
        if not os.path.exists(model_path):
            print(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
            continue
        
        try:
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
            checkpoint = torch.load(model_path, map_location=device)
            config = checkpoint['config']
            
            # ëª¨ë¸ ìƒì„± ë° ê°€ì¤‘ì¹˜ ë¡œë“œ
            model = get_model(config)
            model.load_state_dict(checkpoint['model_state_dict'])
            model.to(device)
            model.eval()
            
            models[model_name] = {
                'model': model,
                'weight': weight,
                'config': config,
                'val_loss': info['val_loss'],
                'description': description
            }
            
            print(f"âœ… {model_name}: {description}")
            print(f"   ê°€ì¤‘ì¹˜: {weight}%, Val Loss: {info['val_loss']:.4f}")
            
        except Exception as e:
            print(f"âŒ {model_name} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            continue
    
    return models

def create_test_dataloader(test_df, img_size, batch_size=16):
    """í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œë” ìƒì„± (ëª¨ë¸ë³„ ì´ë¯¸ì§€ í¬ê¸° ëŒ€ì‘)"""
    test_transform = get_valid_transforms(img_size)
    test_dataset = CarDataset(test_df, transform=test_transform, mode='test')
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=0,  # MPS ìµœì í™”
        pin_memory=True
    )
    
    return test_loader

def apply_tta_transform(images, tta_step):
    """ğŸš€ TTA 5ë‹¨ê³„ ë³€í™˜ ì ìš© (ì„±ëŠ¥ ê·¹ëŒ€í™”)"""
    if tta_step == 0:
        # ì›ë³¸ ì´ë¯¸ì§€
        return images
    elif tta_step == 1:
        # ìˆ˜í‰ ë’¤ì§‘ê¸° (HorizontalFlip)
        return torch.flip(images, dims=[3])
    elif tta_step == 2:
        # ìˆ˜ì§ ë’¤ì§‘ê¸° (VerticalFlip)
        return torch.flip(images, dims=[2])
    elif tta_step == 3:
        # ìˆ˜í‰ + ìˆ˜ì§ ë’¤ì§‘ê¸° (Both Flip)
        return torch.flip(images, dims=[2, 3])
    elif tta_step == 4:
        # 90ë„ íšŒì „ (Rotate 90)
        return torch.rot90(images, k=1, dims=[2, 3])
    else:
        return images

def predict_single_model_with_tta(model, dataloader, device, model_name, tta_steps=5):
    """ğŸ¯ TTAë¥¼ ì ìš©í•œ ë‹¨ì¼ ëª¨ë¸ ì˜ˆì¸¡ (SOTA ì„±ëŠ¥)"""
    model.eval()
    all_predictions = []
    
    print(f"ğŸ”„ {model_name} TTA ì˜ˆì¸¡ ì¤‘ (TTA steps: {tta_steps})")
    
    with torch.no_grad():
        for batch in tqdm(dataloader, desc=f"TTA Predicting {model_name}"):
            images = batch[0].to(device)
            batch_size = images.size(0)
            
            # TTA ì˜ˆì¸¡ë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
            tta_predictions = []
            
            for tta_step in range(tta_steps):
                # TTA ë³€í™˜ ì ìš©
                augmented_images = apply_tta_transform(images, tta_step)
                
                # ëª¨ë¸ ì˜ˆì¸¡
                outputs = model(augmented_images)
                batch_pred = F.softmax(outputs, dim=1)
                tta_predictions.append(batch_pred.cpu().numpy())
            
            # TTA ì˜ˆì¸¡ë“¤ì˜ í‰ê·  (ì•™ìƒë¸” íš¨ê³¼)
            tta_avg = np.mean(tta_predictions, axis=0)
            all_predictions.append(tta_avg)
    
    return np.vstack(all_predictions)

def ensemble_predict_sota(models, test_df, device, use_tta=True, tta_steps=5):
    """ğŸ† SOTA ì•™ìƒë¸” ì˜ˆì¸¡ (TTA + ê°€ì¤‘ í‰ê· )"""
    print("ğŸš€ SOTA ì•™ìƒë¸” ì˜ˆì¸¡ ì‹œì‘!")
    print("=" * 60)
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìˆ˜: {len(test_df)}")
    print(f"ğŸ”„ TTA í™œì„±í™”: {use_tta}")
    print(f"ğŸ¯ TTA Steps: {tta_steps if use_tta else 1}")
    print(f"ğŸ† ì•™ìƒë¸” ëª¨ë¸ ìˆ˜: {len(models)}")
    print("=" * 60)
    
    all_model_predictions = []
    weights = []
    
    for model_name, model_info in models.items():
        print(f"\nğŸ“Š {model_name} ì˜ˆì¸¡ ì¤‘...")
        print(f"ğŸ“ {model_info['description']}")
        
        model = model_info['model']
        weight = model_info['weight']
        config = model_info['config']
        
        # í•´ë‹¹ ëª¨ë¸ì˜ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë°ì´í„°ë¡œë” ìƒì„±
        img_size = config['data']['img_size']
        print(f"ğŸ”§ ì´ë¯¸ì§€ í¬ê¸°: {img_size}x{img_size}")
        
        # ë°°ì¹˜ í¬ê¸° ìµœì í™” (TTAë¡œ ì¸í•œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€ ê³ ë ¤)
        if img_size >= 480:
            batch_size = 8   # ê³ í•´ìƒë„
        elif img_size >= 384:
            batch_size = 12  # ì¤‘í•´ìƒë„
        else:
            batch_size = 16  # í‘œì¤€ í•´ìƒë„
        
        test_loader = create_test_dataloader(test_df, img_size, batch_size)
        
        # TTA ì ìš© ì˜ˆì¸¡ ìˆ˜í–‰
        if use_tta:
            predictions = predict_single_model_with_tta(
                model, test_loader, device, model_name, tta_steps
            )
        else:
            predictions = predict_single_model_with_tta(
                model, test_loader, device, model_name, tta_steps=1
            )
        
        all_model_predictions.append(predictions)
        weights.append(weight)
        
        print(f"âœ… {model_name} ì˜ˆì¸¡ ì™„ë£Œ: {predictions.shape}")
        print(f"ğŸ¯ ê°€ì¤‘ì¹˜: {weight}%")
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        torch.cuda.empty_cache() if torch.cuda.is_available() else None
    
    # ğŸ† ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì•™ìƒë¸” (SOTA ê¸°ë²•)
    print("\nğŸ”„ SOTA ì•™ìƒë¸” ê²°í•© ì¤‘...")
    weights = np.array(weights)
    weights = weights / weights.sum()  # ì •ê·œí™”
    
    print("ğŸ“Š ìµœì¢… ê°€ì¤‘ì¹˜ ë¶„í¬:")
    for i, (model_name, weight) in enumerate(zip(models.keys(), weights)):
        print(f"  â€¢ {model_name}: {weight*100:.1f}%")
    
    # ê°€ì¤‘ ì•™ìƒë¸” ê³„ì‚°
    ensemble_predictions = np.zeros_like(all_model_predictions[0])
    for pred, weight in zip(all_model_predictions, weights):
        ensemble_predictions += pred * weight
    
    # ìµœì¢… ì˜ˆì¸¡ í´ë˜ìŠ¤
    ensemble_classes = np.argmax(ensemble_predictions, axis=1)
    
    # ğŸ¯ ì„±ëŠ¥ ë¶„ì„
    confidence_scores = np.max(ensemble_predictions, axis=1)
    avg_confidence = np.mean(confidence_scores)
    
    print(f"\nğŸ‰ SOTA ì•™ìƒë¸” ì˜ˆì¸¡ ì™„ë£Œ!")
    print(f"ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼: {ensemble_predictions.shape}")
    print(f"ğŸ¯ í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.4f}")
    
    if use_tta:
        print(f"ğŸš€ TTA {tta_steps}ë‹¨ê³„ ì ìš©ìœ¼ë¡œ ì„±ëŠ¥ ê·¹ëŒ€í™”!")
        print(f"ğŸ’ª ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ: 1-2% (TTA íš¨ê³¼)")
    
    # ì‹ ë¢°ë„ ë¶„ì„
    high_confidence = np.sum(confidence_scores > 0.8)
    medium_confidence = np.sum((confidence_scores > 0.5) & (confidence_scores <= 0.8))
    low_confidence = np.sum(confidence_scores <= 0.5)
    
    print(f"\nğŸ“ˆ ì‹ ë¢°ë„ ë¶„ì„:")
    print(f"  ğŸŸ¢ ë†’ìŒ (>0.8): {high_confidence} ({high_confidence/len(test_df)*100:.1f}%)")
    print(f"  ğŸŸ¡ ì¤‘ê°„ (0.5-0.8): {medium_confidence} ({medium_confidence/len(test_df)*100:.1f}%)")
    print(f"  ğŸ”´ ë‚®ìŒ (<0.5): {low_confidence} ({low_confidence/len(test_df)*100:.1f}%)")
    
    return ensemble_predictions, ensemble_classes

def create_submission(test_df, predictions, class_info, output_path):
    """ì œì¶œ íŒŒì¼ ìƒì„± (SOTA í˜•ì‹)"""
    # í´ë˜ìŠ¤ ì¸ë±ìŠ¤ë¥¼ í´ë˜ìŠ¤ëª…ìœ¼ë¡œ ë³€í™˜
    label_to_class = class_info['label_to_class']
    predicted_classes = [label_to_class[str(pred)] for pred in predictions]
    
    # ì œì¶œ ë°ì´í„°í”„ë ˆì„ ìƒì„±
    submission_df = pd.DataFrame({
        'id': test_df['id'],
        'class': predicted_classes
    })
    
    # CSV ì €ì¥
    submission_df.to_csv(output_path, index=False)
    print(f"ğŸ“ ì œì¶œ íŒŒì¼ ì €ì¥: {output_path}")
    
    # í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„
    class_counts = submission_df['class'].value_counts()
    print(f"\nğŸ“Š ì˜ˆì¸¡ í´ë˜ìŠ¤ ë¶„í¬ (ìƒìœ„ 10ê°œ):")
    for i, (class_name, count) in enumerate(class_counts.head(10).items()):
        print(f"  {i+1}. {class_name}: {count}ê°œ ({count/len(submission_df)*100:.1f}%)")
    
    return submission_df

def main():
    parser = argparse.ArgumentParser(description='SOTA ì•™ìƒë¸” ì¶”ë¡ ')
    parser.add_argument('--ensemble_results', type=str, 
                       default='outputs/ensemble/ensemble_results_fold_0.json',
                       help='ì•™ìƒë¸” ê²°ê³¼ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--config', type=str, default='config/config_sota.yaml',
                       help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--tta_steps', type=int, default=5,
                       help='TTA ë‹¨ê³„ ìˆ˜ (1-5)')
    parser.add_argument('--output', type=str, default='outputs/submissions/sota_submission.csv',
                       help='ì œì¶œ íŒŒì¼ ê²½ë¡œ')
    args = parser.parse_args()
    
    print("ğŸš€ ì°¨ëŸ‰ ë¶„ë¥˜ SOTA ì•™ìƒë¸” ì¶”ë¡  ì‹œì‘!")
    print("=" * 60)
    print("ğŸ¯ ëª©í‘œ: Kaggle ìƒìœ„ 1% ì†”ë£¨ì…˜ (Log Loss < 1.5)")
    print("ğŸ† ìµœì‹  ë”¥ëŸ¬ë‹ ê¸°ë²• ì´ë™ì›!")
    print("=" * 60)
    
    # ì„¤ì • ë¡œë“œ
    with open(args.config, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    print(f"ğŸ“‹ í”„ë¡œì íŠ¸: {config['project']['name']} v{config['project']['version']}")
    print(f"ğŸ“ ì„¤ëª…: {config['project']['description']}")
    print(f"ğŸ¯ ëª©í‘œ ì„±ëŠ¥: {config['project']['target_performance']}")
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = setup_device()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
    test_df = pd.read_csv(config['data']['test_csv'])
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_df)}ê°œ ì´ë¯¸ì§€")
    
    # í´ë˜ìŠ¤ ì •ë³´ ë¡œë“œ
    with open('data/class_info.json', 'r', encoding='utf-8') as f:
        class_info = json.load(f)
    
    print(f"ğŸ·ï¸ í´ë˜ìŠ¤ ìˆ˜: {len(class_info['label_to_class'])}ê°œ")
    
    # ì•™ìƒë¸” ëª¨ë¸ ë¡œë“œ
    models = load_ensemble_models(args.ensemble_results, device)
    
    if not models:
        print("âŒ ë¡œë“œëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    print(f"\nğŸ† SOTA ì•™ìƒë¸” êµ¬ì„±: {len(models)}ê°œ ëª¨ë¸")
    
    # TTA ì„¤ì •
    use_tta = args.tta_steps > 1
    print(f"\nğŸš€ TTA ì„¤ì •:")
    print(f"  í™œì„±í™”: {use_tta}")
    print(f"  ë‹¨ê³„ ìˆ˜: {args.tta_steps}")
    
    if use_tta:
        print(f"  ë³€í™˜ ì¢…ë¥˜:")
        transforms = ["ì›ë³¸", "ìˆ˜í‰ë’¤ì§‘ê¸°", "ìˆ˜ì§ë’¤ì§‘ê¸°", "ì–‘ë°©í–¥ë’¤ì§‘ê¸°", "90ë„íšŒì „"]
        for i in range(args.tta_steps):
            print(f"    {i+1}. {transforms[i]}")
    
    # SOTA ì•™ìƒë¸” ì˜ˆì¸¡
    ensemble_predictions, ensemble_classes = ensemble_predict_sota(
        models, test_df, device, use_tta, args.tta_steps
    )
    
    # ì œì¶œ íŒŒì¼ ìƒì„±
    output_dir = Path(args.output).parent
    output_dir.mkdir(parents=True, exist_ok=True)
    
    submission_df = create_submission(
        test_df, ensemble_classes, class_info, args.output
    )
    
    # ğŸ¯ ì„±ëŠ¥ ì˜ˆì¸¡
    print(f"\nğŸ† SOTA ì„±ëŠ¥ ì˜ˆì¸¡:")
    
    # ê°œë³„ ëª¨ë¸ ì„±ëŠ¥ ê¸°ë°˜ ì˜ˆì¸¡
    individual_losses = [info['val_loss'] for info in models.values()]
    weights = [info['weight'] for info in models.values()]
    
    weighted_avg_loss = np.average(individual_losses, weights=weights)
    ensemble_expected_loss = weighted_avg_loss * 0.85  # 15% ì•™ìƒë¸” í–¥ìƒ
    
    if use_tta:
        tta_expected_loss = ensemble_expected_loss * 0.92  # 8% TTA í–¥ìƒ
        final_expected_loss = tta_expected_loss
        print(f"  ğŸ“Š ê°œë³„ ëª¨ë¸ í‰ê· : {weighted_avg_loss:.4f}")
        print(f"  ğŸ”„ ì•™ìƒë¸” íš¨ê³¼: {ensemble_expected_loss:.4f} (15% í–¥ìƒ)")
        print(f"  ğŸš€ TTA íš¨ê³¼: {tta_expected_loss:.4f} (8% ì¶”ê°€ í–¥ìƒ)")
        print(f"  ğŸ† ìµœì¢… ì˜ˆìƒ ì„±ëŠ¥: {final_expected_loss:.4f}")
    else:
        final_expected_loss = ensemble_expected_loss
        print(f"  ğŸ“Š ê°œë³„ ëª¨ë¸ í‰ê· : {weighted_avg_loss:.4f}")
        print(f"  ğŸ”„ ì•™ìƒë¸” íš¨ê³¼: {ensemble_expected_loss:.4f} (15% í–¥ìƒ)")
        print(f"  ğŸ† ìµœì¢… ì˜ˆìƒ ì„±ëŠ¥: {final_expected_loss:.4f}")
    
    # ëª©í‘œ ë‹¬ì„± ì—¬ë¶€
    target_loss = 1.5
    if final_expected_loss < target_loss:
        print(f"ğŸ¥‡ ëª©í‘œ ë‹¬ì„±! (Log Loss < {target_loss})")
        print("ğŸ† Kaggle ìƒìœ„ 1% ì§„ì… ê°€ëŠ¥!")
    else:
        gap = final_expected_loss - target_loss
        print(f"âš¡ ëª©í‘œê¹Œì§€ {gap:.4f} ë¶€ì¡±")
        print("ğŸ”§ ì¶”ê°€ ìµœì í™” ê¶Œì¥")
    
    print(f"\nğŸ‰ SOTA ì•™ìƒë¸” ì¶”ë¡  ì™„ë£Œ!")
    print(f"ğŸ“ ì œì¶œ íŒŒì¼: {args.output}")

if __name__ == "__main__":
    main() 