"""
ë©”ì¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ - ê°„ì†Œí™” ë° ì•ˆì •í™” ë²„ì „
"""

import os
import sys
import argparse
import yaml
import json
import numpy as np
import pandas as pd
from pathlib import Path
from datetime import datetime
from tqdm import tqdm
import signal
import gc

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from sklearn.model_selection import StratifiedKFold

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.data.dataset import CarDataset, get_train_transforms, get_valid_transforms
from src.models.backbone import get_model
from src.training.losses import get_loss_fn
from src.utils.metrics import compute_metrics

# ì „ì—­ ë³€ìˆ˜ë¡œ ì •ë¦¬ í”Œë˜ê·¸ ì„¤ì •
cleanup_flag = False

def signal_handler(signum, frame):
    """KeyboardInterrupt ì²˜ë¦¬"""
    global cleanup_flag
    print("\nğŸ›‘ í•™ìŠµ ì¤‘ë‹¨ ì‹ í˜¸ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤. ì•ˆì „í•˜ê²Œ ì •ë¦¬ ì¤‘...")
    cleanup_flag = True

# ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ë“±ë¡
signal.signal(signal.SIGINT, signal_handler)

def get_optimizer(model, config):
    """ì˜µí‹°ë§ˆì´ì € ìƒì„±"""
    lr = config['training']['learning_rate']
    weight_decay = config['training']['weight_decay']
    return optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)

def get_scheduler(optimizer, config):
    """ìŠ¤ì¼€ì¤„ëŸ¬ ìƒì„±"""
    return optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=3, min_lr=1e-6
    )

def train_epoch(model, loader, criterion, optimizer, device):
    """1 ì—í­ í•™ìŠµ"""
    global cleanup_flag
    
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    
    pbar = tqdm(loader, desc='Training')
    for batch_idx, (images, targets) in enumerate(pbar):
        # ì¤‘ë‹¨ ì‹ í˜¸ í™•ì¸
        if cleanup_flag:
            print("ğŸ›‘ í•™ìŠµ ì¤‘ë‹¨ë¨")
            break
            
        images, targets = images.to(device), targets.to(device)
        
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
        _, predicted = outputs.max(1)
        total += targets.size(0)
        correct += predicted.eq(targets).sum().item()
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬ (ë§¤ 100 ë°°ì¹˜ë§ˆë‹¤)
        if batch_idx % 100 == 0:
            if torch.backends.mps.is_available():
                torch.mps.empty_cache()
        
        pbar.set_postfix({
            'loss': running_loss / (batch_idx + 1),
            'acc': 100. * correct / total
        })
    
    return running_loss / len(loader), 100. * correct / total

def validate(model, loader, criterion, device):
    """ê²€ì¦"""
    global cleanup_flag
    
    model.eval()
    val_loss = 0.0
    all_preds = []
    all_targets = []
    
    with torch.no_grad():
        for images, targets in tqdm(loader, desc='Validation'):
            # ì¤‘ë‹¨ ì‹ í˜¸ í™•ì¸
            if cleanup_flag:
                break
                
            images, targets = images.to(device), targets.to(device)
            outputs = model(images)
            loss = criterion(outputs, targets)
            val_loss += loss.item()
            
            probs = torch.softmax(outputs, dim=1)
            all_preds.append(probs.cpu().numpy())
            all_targets.append(targets.cpu().numpy())
    
    if cleanup_flag:
        return {'loss': float('inf'), 'accuracy': 0.0, 'log_loss': float('inf')}
    
    val_loss /= len(loader)
    all_preds = np.vstack(all_preds)
    all_targets = np.concatenate(all_targets)
    
    # ë©”íŠ¸ë¦­ ê³„ì‚°
    metrics = compute_metrics(all_targets, all_preds, num_classes=396)
    
    return {
        'loss': val_loss,
        'accuracy': metrics['accuracy'],
        'log_loss': metrics['log_loss']
    }

def train_fold(config, fold, train_df):
    """ë‹¨ì¼ Fold í•™ìŠµ"""
    global cleanup_flag
    
    print(f"\nğŸš€ Fold {fold} í•™ìŠµ ì‹œì‘")
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    if torch.backends.mps.is_available():
        device = torch.device('mps')
        print("âœ… Apple Silicon GPU (MPS) ì‚¬ìš©")
    else:
        device = torch.device('cpu')
        print("âš ï¸ CPU ì‚¬ìš©")
    
    # K-Fold ë¶„í•  (ê°œì„ ëœ ë²„ì „)
    print(f"ğŸ“Š ì „ì²´ ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸...")
    unique_classes = train_df['label'].unique()
    print(f"ğŸ“Š ì „ì²´ í´ë˜ìŠ¤ ìˆ˜: {len(unique_classes)} (ë²”ìœ„: {unique_classes.min()}-{unique_classes.max()})")
    
    # í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ í™•ì¸
    class_counts = train_df['label'].value_counts().sort_index()
    min_samples = class_counts.min()
    print(f"ğŸ“Š í´ë˜ìŠ¤ë³„ ìµœì†Œ ìƒ˜í”Œ ìˆ˜: {min_samples}")
    
    if min_samples < 5:
        print(f"âš ï¸ ì¼ë¶€ í´ë˜ìŠ¤ì˜ ìƒ˜í”Œ ìˆ˜ê°€ ë§¤ìš° ì ìŠµë‹ˆë‹¤ (ìµœì†Œ: {min_samples})")
        print("âš ï¸ ì´ë¡œ ì¸í•´ ì¼ë¶€ foldì—ì„œ í´ë˜ìŠ¤ê°€ ëˆ„ë½ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    # StratifiedKFold with improved parameters
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    
    # ê° foldì˜ í´ë˜ìŠ¤ ë¶„í¬ ë¯¸ë¦¬ í™•ì¸
    print(f"ğŸ” Fold {fold} í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸ ì¤‘...")
    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['label'])):
        if fold_idx == fold:
            val_classes = train_df.iloc[val_idx]['label'].unique()
            train_classes = train_df.iloc[train_idx]['label'].unique()
            
            print(f"ğŸ“Š Fold {fold} - í•™ìŠµ ë°ì´í„° í´ë˜ìŠ¤ ìˆ˜: {len(train_classes)}")
            print(f"ğŸ“Š Fold {fold} - ê²€ì¦ ë°ì´í„° í´ë˜ìŠ¤ ìˆ˜: {len(val_classes)}")
            
            missing_in_val = set(unique_classes) - set(val_classes)
            missing_in_train = set(unique_classes) - set(train_classes)
            
            if missing_in_val:
                print(f"âš ï¸ ê²€ì¦ ë°ì´í„°ì— ëˆ„ë½ëœ í´ë˜ìŠ¤ ìˆ˜: {len(missing_in_val)}")
                print(f"âš ï¸ ëˆ„ë½ëœ í´ë˜ìŠ¤ ì˜ˆì‹œ: {sorted(list(missing_in_val))[:10]}")
            
            if missing_in_train:
                print(f"âš ï¸ í•™ìŠµ ë°ì´í„°ì— ëˆ„ë½ëœ í´ë˜ìŠ¤ ìˆ˜: {len(missing_in_train)}")
            
            break
        
        if fold_idx != fold:
            continue
        
        # ì¤‘ë‹¨ ì‹ í˜¸ í™•ì¸
        if cleanup_flag:
            print("ğŸ›‘ í•™ìŠµ ì¤‘ë‹¨ë¨")
            return
        
        # ë°ì´í„° ë¶„í• 
        train_data = train_df.iloc[train_idx].reset_index(drop=True)
        val_data = train_df.iloc[val_idx].reset_index(drop=True)
        
        print(f"ğŸ“Š Train: {len(train_data)}, Val: {len(val_data)}")
        
        # ë°ì´í„° ë³€í™˜
        img_size = config['data']['img_size']
        train_transform = get_train_transforms(img_size)
        val_transform = get_valid_transforms(img_size)
        
        # ë°ì´í„°ì…‹
        train_dataset = CarDataset(train_data, transform=train_transform, mode='train')
        val_dataset = CarDataset(val_data, transform=val_transform, mode='train')
        
        # macOSì—ì„œ ì•ˆì •ì„±ì„ ìœ„í•´ num_workers ì¡°ì •
        num_workers = 0 if device.type == 'mps' else 2
        use_pin_memory = device.type != 'mps'
        
        # ë°ì´í„°ë¡œë”
        train_loader = DataLoader(
            train_dataset,
            batch_size=config['training']['batch_size'],
            shuffle=True,
            num_workers=num_workers,
            pin_memory=use_pin_memory,
            drop_last=True,
            persistent_workers=False
        )
        
        val_loader = DataLoader(
            val_dataset,
            batch_size=config['training']['batch_size'],
            shuffle=False,
            num_workers=num_workers,
            pin_memory=use_pin_memory,
            persistent_workers=False
        )
        
        # ëª¨ë¸ ìƒì„±
        model = get_model(config).to(device)
        criterion = get_loss_fn(config)
        optimizer = get_optimizer(model, config)
        scheduler = get_scheduler(optimizer, config)
        
        # í•™ìŠµ ë£¨í”„
        best_log_loss = float('inf')
        save_dir = config['logging']['save_dir']
        os.makedirs(f"{save_dir}/fold_{fold}", exist_ok=True)
        
        try:
            for epoch in range(config['training']['epochs']):
                # ì¤‘ë‹¨ ì‹ í˜¸ í™•ì¸
                if cleanup_flag:
                    print("ğŸ›‘ í•™ìŠµ ì¤‘ë‹¨ë¨")
                    break
                    
                print(f"\n=== Epoch {epoch+1}/{config['training']['epochs']} ===")
                
                # í•™ìŠµ
                train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)
                
                if cleanup_flag:
                    break
                
                # ê²€ì¦
                val_metrics = validate(model, val_loader, criterion, device)
                
                if cleanup_flag:
                    break
                
                print(f"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%")
                print(f"Val Loss: {val_metrics['loss']:.4f}, Val Acc: {val_metrics['accuracy']:.2f}%")
                print(f"Val Log Loss: {val_metrics['log_loss']:.4f}")
                
                # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
                scheduler.step(val_metrics['loss'])
                
                # ìµœê³  ëª¨ë¸ ì €ì¥
                if val_metrics['log_loss'] < best_log_loss:
                    best_log_loss = val_metrics['log_loss']
                    torch.save({
                        'epoch': epoch,
                        'model_state_dict': model.state_dict(),
                        'val_log_loss': val_metrics['log_loss'],
                        'config': config
                    }, f"{save_dir}/fold_{fold}/best_model.pth")
                    print(f"âœ… ìµœê³  ëª¨ë¸ ì €ì¥: Log Loss = {best_log_loss:.4f}")
            
            if not cleanup_flag:
                print(f"\nğŸ‰ Fold {fold} í•™ìŠµ ì™„ë£Œ! ìµœê³  Log Loss: {best_log_loss:.4f}")
                
        except KeyboardInterrupt:
            print("ğŸ›‘ KeyboardInterrupt ê°ì§€ë¨")
            cleanup_flag = True
        except Exception as e:
            print(f"âŒ í•™ìŠµ ì¤‘ ì˜¤ë¥˜: {e}")
        finally:
            # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
            del model, train_loader, val_loader
            if torch.backends.mps.is_available():
                torch.mps.empty_cache()
            gc.collect()
        
        break

def main():
    parser = argparse.ArgumentParser(description='Train Car Classification Model (Stable)')
    parser.add_argument('--config', type=str, default='config/config.yaml')
    parser.add_argument('--fold', type=int, default=0)
    args = parser.parse_args()
    
    try:
        # ì„¤ì • ë¡œë“œ
        with open(args.config, 'r') as f:
            config = yaml.safe_load(f)
        
        # ë°ì´í„° ë¡œë“œ
        train_df_path = os.path.join(config['logging']['save_dir'], 'data', 'train_df.csv')
        
        if not os.path.exists(train_df_path):
            print("âŒ í•™ìŠµ ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        train_df = pd.read_csv(train_df_path)
        print(f"ğŸ“Š ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(train_df)}ê°œ ì´ë¯¸ì§€")
        
        # í•™ìŠµ ì‹œì‘
        train_fold(config, args.fold, train_df)
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ í”„ë¡œê·¸ë¨ì´ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
    finally:
        print("\nğŸ§¹ ìµœì¢… ì •ë¦¬ ì¤‘...")
        if torch.backends.mps.is_available():
            torch.mps.empty_cache()
        gc.collect()
        print("âœ… í”„ë¡œê·¸ë¨ ì¢…ë£Œ")

if __name__ == "__main__":
    main()
