#!/usr/bin/env python3
"""
ğŸš€ ì°¨ëŸ‰ ë¶„ë¥˜ ì•™ìƒë¸” í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ - ì‚¬ìš©ì ì¶”ì²œ ëª¨ë¸ êµ¬ì„± (ì•ˆì •í™” ë²„ì „)
"""

import os
import sys
import yaml
import json
import argparse
import pandas as pd
import numpy as np
from pathlib import Path
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from sklearn.model_selection import StratifiedKFold
from tqdm import tqdm
import signal
import gc
import copy

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

from src.models.backbone import get_model
from src.data.dataset import CarDataset, get_train_transforms, get_valid_transforms
from src.utils.metrics import compute_metrics
from src.training.losses import get_loss_fn

# ì „ì—­ ë³€ìˆ˜ë¡œ ì •ë¦¬ í”Œë˜ê·¸ ì„¤ì •
cleanup_flag = False

def signal_handler(signum, frame):
    """KeyboardInterrupt ì²˜ë¦¬"""
    global cleanup_flag
    print("\nğŸ›‘ í•™ìŠµ ì¤‘ë‹¨ ì‹ í˜¸ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤. ì•ˆì „í•˜ê²Œ ì •ë¦¬ ì¤‘...")
    cleanup_flag = True

# ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ë“±ë¡
signal.signal(signal.SIGINT, signal_handler)

# ğŸ† ì‚¬ìš©ì ì¶”ì²œ ì•™ìƒë¸” ëª¨ë¸ êµ¬ì„± (5ê°œ ëª¨ë¸)
ENSEMBLE_MODELS = {
    "efficientnetv2_l": {
        "backbone": "tf_efficientnetv2_l.in21k_ft_in1k",
        "img_size": 384,
        "batch_size": 24,
        "learning_rate": 0.004,
        "weight": 0.25,  # 25%
        "description": "EfficientNetV2-L: íš¨ìœ¨ì„±ê³¼ ì„±ëŠ¥ì˜ ì™„ë²½í•œ ê· í˜•"
    },
    "convnext_large": {
        "backbone": "convnext_large.fb_in22k_ft_in1k_384", 
        "img_size": 384,
        "batch_size": 20,
        "learning_rate": 0.003,
        "weight": 0.25,  # 25%
        "description": "ConvNeXt Large: ìµœì‹  CNN ì•„í‚¤í…ì²˜ì˜ ì •ì "
    },
    "swin_large": {
        "backbone": "swin_large_patch4_window12_384.ms_in22k_ft_in1k",
        "img_size": 384,
        "batch_size": 18,
        "learning_rate": 0.003,
        "weight": 0.20,  # 20%
        "description": "Swin Transformer Large: ìœˆë„ìš° ê¸°ë°˜ ì–´í…ì…˜"
    },
    "resnet152": {
        "backbone": "resnet152.a1_in1k",
        "img_size": 224,  # ResNetì€ 224ê°€ ìµœì 
        "batch_size": 32,
        "learning_rate": 0.005,
        "weight": 0.15,  # 15%
        "description": "ResNet152: ê²€ì¦ëœ í´ë˜ì‹ ì•„í‚¤í…ì²˜"
    },
    "inception_v4": {
        "backbone": "inception_v4.tf_in1k",
        "img_size": 299,  # Inceptionì€ 299ê°€ ìµœì 
        "batch_size": 28,
        "learning_rate": 0.004,
        "weight": 0.15,  # 15%
        "description": "Inception-v4: ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ íŠ¹ì§• ì¶”ì¶œì˜ ëŒ€ê°€"
    }
}

def create_model_config(base_config, model_info, model_name):
    """ëª¨ë¸ë³„ ì„¤ì • ìƒì„± (ê¹Šì€ ë³µì‚¬ ì‚¬ìš©)"""
    config = copy.deepcopy(base_config)  # ê¹Šì€ ë³µì‚¬ë¡œ ì¤‘ì²© ë”•ì…”ë„ˆë¦¬ ì•ˆì „í•˜ê²Œ ë³µì‚¬
    config['model']['backbone'] = model_info['backbone']
    config['data']['img_size'] = model_info['img_size']
    config['training']['batch_size'] = model_info['batch_size']
    config['training']['learning_rate'] = model_info['learning_rate']
    return config

def cleanup_resources(model=None, train_loader=None, val_loader=None):
    """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
    try:
        if model is not None:
            del model
        if train_loader is not None:
            del train_loader
        if val_loader is not None:
            del val_loader
        
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        elif torch.backends.mps.is_available():
            torch.mps.empty_cache()
        
        # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
        gc.collect()
        print("ğŸ§¹ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

def train_single_model(config, model_name, fold, train_df):
    """ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ (ì•ˆì •í™” ë²„ì „)"""
    global cleanup_flag
    
    model_info = ENSEMBLE_MODELS[model_name]
    print(f"\nğŸš€ {model_name.upper()} ëª¨ë¸ í•™ìŠµ ì‹œì‘ (Fold {fold})")
    print(f"ğŸ“ {model_info['description']}")
    print(f"ğŸ”§ ì„¤ì •: {model_info['backbone']}, ì´ë¯¸ì§€í¬ê¸°={model_info['img_size']}, ë°°ì¹˜={model_info['batch_size']}")
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    if torch.backends.mps.is_available():
        device = torch.device('mps')
        print("âœ… Apple Silicon GPU (MPS) ì‚¬ìš©")
    else:
        device = torch.device('cpu')
        print("âš ï¸ CPU ì‚¬ìš©")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    save_dir = f"outputs/ensemble/{model_name}"
    os.makedirs(f"{save_dir}/fold_{fold}", exist_ok=True)
    
    # K-Fold ë¶„í•  (ê°œì„ ëœ ë²„ì „)
    print(f"ğŸ“Š ì „ì²´ ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸...")
    unique_classes = train_df['label'].unique()
    print(f"ğŸ“Š ì „ì²´ í´ë˜ìŠ¤ ìˆ˜: {len(unique_classes)} (ë²”ìœ„: {unique_classes.min()}-{unique_classes.max()})")
    
    # í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ í™•ì¸
    class_counts = train_df['label'].value_counts().sort_index()
    min_samples = class_counts.min()
    print(f"ğŸ“Š í´ë˜ìŠ¤ë³„ ìµœì†Œ ìƒ˜í”Œ ìˆ˜: {min_samples}")
    
    if min_samples < 5:
        print(f"âš ï¸ ì¼ë¶€ í´ë˜ìŠ¤ì˜ ìƒ˜í”Œ ìˆ˜ê°€ ë§¤ìš° ì ìŠµë‹ˆë‹¤ (ìµœì†Œ: {min_samples})")
        print("âš ï¸ ì´ë¡œ ì¸í•´ ì¼ë¶€ foldì—ì„œ í´ë˜ìŠ¤ê°€ ëˆ„ë½ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    # StratifiedKFold with improved parameters
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    
    # ê° foldì˜ í´ë˜ìŠ¤ ë¶„í¬ ë¯¸ë¦¬ í™•ì¸
    print(f"ğŸ” Fold {fold} í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸ ì¤‘...")
    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['label'])):
        if fold_idx == fold:
            val_classes = train_df.iloc[val_idx]['label'].unique()
            train_classes = train_df.iloc[train_idx]['label'].unique()
            
            print(f"ğŸ“Š Fold {fold} - í•™ìŠµ ë°ì´í„° í´ë˜ìŠ¤ ìˆ˜: {len(train_classes)}")
            print(f"ğŸ“Š Fold {fold} - ê²€ì¦ ë°ì´í„° í´ë˜ìŠ¤ ìˆ˜: {len(val_classes)}")
            
            missing_in_val = set(unique_classes) - set(val_classes)
            missing_in_train = set(unique_classes) - set(train_classes)
            
            if missing_in_val:
                print(f"âš ï¸ ê²€ì¦ ë°ì´í„°ì— ëˆ„ë½ëœ í´ë˜ìŠ¤ ìˆ˜: {len(missing_in_val)}")
                print(f"âš ï¸ ëˆ„ë½ëœ í´ë˜ìŠ¤ ì˜ˆì‹œ: {sorted(list(missing_in_val))[:10]}")
            
            if missing_in_train:
                print(f"âš ï¸ í•™ìŠµ ë°ì´í„°ì— ëˆ„ë½ëœ í´ë˜ìŠ¤ ìˆ˜: {len(missing_in_train)}")
            
            break
    
    model = None
    train_loader = None
    val_loader = None
    
    try:
        for fold_idx, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['label'])):
            if fold_idx != fold:
                continue
                
            # ì¤‘ë‹¨ ì‹ í˜¸ í™•ì¸
            if cleanup_flag:
                print("ğŸ›‘ í•™ìŠµ ì¤‘ë‹¨ë¨")
                return None, float('inf')
                
            # ë°ì´í„°ì…‹ ë¶„í• 
            train_data = train_df.iloc[train_idx].reset_index(drop=True)
            val_data = train_df.iloc[val_idx].reset_index(drop=True)
            
            print(f"ğŸ“Š Train: {len(train_data)}, Val: {len(val_data)}")
            
            # ë³€í™˜ ì„¤ì •
            img_size = config['data']['img_size']
            train_transform = get_train_transforms(img_size)
            val_transform = get_valid_transforms(img_size)
            
            # ë°ì´í„°ì…‹ ë° ë¡œë”
            train_dataset = CarDataset(train_data, transform=train_transform, mode='train')
            val_dataset = CarDataset(val_data, transform=val_transform, mode='train')
            
            # macOSì—ì„œ ì•ˆì •ì„±ì„ ìœ„í•´ num_workers ì¡°ì •
            num_workers = 0 if device.type == 'mps' else 2  # MPSì—ì„œëŠ” 0, ê·¸ ì™¸ëŠ” 2
            use_pin_memory = device.type != 'mps'
            
            train_loader = DataLoader(
                train_dataset,
                batch_size=config['training']['batch_size'],
                shuffle=True,
                num_workers=num_workers,
                pin_memory=use_pin_memory,
                drop_last=True,
                persistent_workers=False  # ì•ˆì •ì„± í–¥ìƒ
            )
            
            val_loader = DataLoader(
                val_dataset,
                batch_size=config['training']['batch_size'],
                shuffle=False,
                num_workers=num_workers,
                pin_memory=use_pin_memory,
                persistent_workers=False  # ì•ˆì •ì„± í–¥ìƒ
            )
            
            # ëª¨ë¸ ìƒì„±
            model = get_model(config).to(device)
            criterion = get_loss_fn(config)
            optimizer = optim.AdamW(
                model.parameters(), 
                lr=config['training']['learning_rate'], 
                weight_decay=0.05
            )
            scheduler = optim.lr_scheduler.ReduceLROnPlateau(
                optimizer, mode='min', factor=0.5, patience=3, min_lr=1e-6
            )
            
            # í•™ìŠµ ë£¨í”„
            best_val_loss = float('inf')
            best_model_path = f"{save_dir}/fold_{fold}/best_model.pth"
            
            for epoch in range(50):  # ê°„ì†Œí™”: 50 ì—í­
                # ì¤‘ë‹¨ ì‹ í˜¸ í™•ì¸
                if cleanup_flag:
                    print("ğŸ›‘ í•™ìŠµ ì¤‘ë‹¨ë¨")
                    break
                    
                print(f"\n=== Epoch {epoch+1}/50 ===")
                
                # í•™ìŠµ
                model.train()
                train_loss = 0.0
                
                try:
                    for batch_idx, (images, targets) in enumerate(tqdm(train_loader, desc='Training')):
                        # ì¤‘ë‹¨ ì‹ í˜¸ í™•ì¸
                        if cleanup_flag:
                            print("ğŸ›‘ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ë‹¨ë¨")
                            break
                            
                        images, targets = images.to(device), targets.to(device)
                        
                        optimizer.zero_grad()
                        outputs = model(images)
                        loss = criterion(outputs, targets)
                        loss.backward()
                        optimizer.step()
                        
                        train_loss += loss.item()
                        
                        # ë©”ëª¨ë¦¬ ì •ë¦¬ (ë§¤ 100 ë°°ì¹˜ë§ˆë‹¤)
                        if batch_idx % 100 == 0:
                            if torch.backends.mps.is_available():
                                torch.mps.empty_cache()
                    
                    if cleanup_flag:
                        break
                        
                    train_loss /= len(train_loader)
                    
                    # ê²€ì¦
                    model.eval()
                    val_loss = 0.0
                    all_preds = []
                    all_targets = []
                    
                    with torch.no_grad():
                        for images, targets in tqdm(val_loader, desc='Validation'):
                            # ì¤‘ë‹¨ ì‹ í˜¸ í™•ì¸
                            if cleanup_flag:
                                break
                                
                            images, targets = images.to(device), targets.to(device)
                            
                            outputs = model(images)
                            loss = criterion(outputs, targets)
                            val_loss += loss.item()
                            
                            probs = torch.softmax(outputs, dim=1)
                            all_preds.append(probs.cpu().numpy())
                            all_targets.append(targets.cpu().numpy())
                    
                    if cleanup_flag:
                        break
                        
                    val_loss /= len(val_loader)
                    all_preds = np.vstack(all_preds)
                    all_targets = np.concatenate(all_targets)
                    
                    # ë©”íŠ¸ë¦­ ê³„ì‚°
                    metrics = compute_metrics(all_targets, all_preds, num_classes=396)
                    
                    print(f"ğŸ“Š Train Loss: {train_loss:.4f}")
                    print(f"ğŸ“Š Val Loss: {val_loss:.4f}, Val Log Loss: {metrics['log_loss']:.4f}")
                    print(f"ğŸ“Š Val Accuracy: {metrics['accuracy']:.2f}%")
                    
                    # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
                    scheduler.step(val_loss)
                    
                    # ìµœê³  ëª¨ë¸ ì €ì¥
                    if val_loss < best_val_loss:
                        best_val_loss = val_loss
                        torch.save({
                            'epoch': epoch,
                            'model_state_dict': model.state_dict(),
                            'val_loss': val_loss,
                            'val_log_loss': metrics['log_loss'],
                            'config': config
                        }, best_model_path)
                        print(f"âœ… ìµœê³  ëª¨ë¸ ì €ì¥: {best_model_path}")
                        
                except KeyboardInterrupt:
                    print("ğŸ›‘ KeyboardInterrupt ê°ì§€ë¨")
                    cleanup_flag = True
                    break
                except Exception as e:
                    print(f"âŒ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    break
            
            if not cleanup_flag:
                print(f"\nğŸ‰ {model_name} Fold {fold} í•™ìŠµ ì™„ë£Œ!")
                print(f"ğŸ† ìµœê³  ê²€ì¦ Loss: {best_val_loss:.4f}")
            
            return best_model_path, best_val_loss
            
    except Exception as e:
        print(f"âŒ {model_name} í•™ìŠµ ì¤‘ ì˜¤ë¥˜: {e}")
        return None, float('inf')
    finally:
        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        cleanup_resources(model, train_loader, val_loader)

def train_ensemble(base_config_path, fold=0):
    """ì•™ìƒë¸” ëª¨ë¸ë“¤ í•™ìŠµ (ì•ˆì •í™” ë²„ì „)"""
    global cleanup_flag
    
    print("ğŸš€ ì°¨ëŸ‰ ë¶„ë¥˜ ì•™ìƒë¸” í•™ìŠµ ì‹œì‘!")
    print("ğŸ† ì‚¬ìš©ì ì¶”ì²œ 5ê°œ ëª¨ë¸ êµ¬ì„±:")
    
    for model_name, info in ENSEMBLE_MODELS.items():
        print(f"  â€¢ {model_name}: {info['description']} (ê°€ì¤‘ì¹˜: {info['weight']*100}%)")
    
    # ê¸°ë³¸ ì„¤ì • ë¡œë“œ
    with open(base_config_path, 'r') as f:
        base_config = yaml.safe_load(f)
    
    # ë°ì´í„° ë¡œë“œ
    train_df_path = os.path.join(base_config['logging']['save_dir'], 'data', 'train_df.csv')
    
    if not os.path.exists(train_df_path):
        print("âŒ í•™ìŠµ ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    train_df = pd.read_csv(train_df_path)
    print(f"ğŸ“Š ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(train_df)}ê°œ ì´ë¯¸ì§€")
    
    # ì•™ìƒë¸” ê²°ê³¼ ì €ì¥
    ensemble_results = {}
    
    # ê° ëª¨ë¸ í•™ìŠµ
    for model_name, model_info in ENSEMBLE_MODELS.items():
        if cleanup_flag:
            print("ğŸ›‘ ì•™ìƒë¸” í•™ìŠµ ì¤‘ë‹¨ë¨")
            break
            
        try:
            print(f"\n{'='*50}")
            print(f"ğŸ¯ {model_name.upper()} í•™ìŠµ ì‹œì‘")
            print(f"{'='*50}")
            
            # ëª¨ë¸ë³„ ì„¤ì • ìƒì„±
            model_config = create_model_config(base_config, model_info, model_name)
            
            # ëª¨ë¸ í•™ìŠµ
            model_path, val_loss = train_single_model(
                model_config, model_name, fold, train_df
            )
            
            if model_path is not None and not cleanup_flag:
                ensemble_results[model_name] = {
                    'val_loss': val_loss,
                    'weight': model_info['weight'],
                    'model_path': model_path,
                    'backbone': model_info['backbone'],
                    'description': model_info['description']
                }
                
                print(f"âœ… {model_name} í•™ìŠµ ì™„ë£Œ: Val Loss = {val_loss:.4f}")
            else:
                print(f"âŒ {model_name} í•™ìŠµ ì‹¤íŒ¨ ë˜ëŠ” ì¤‘ë‹¨ë¨")
            
        except Exception as e:
            print(f"âŒ {model_name} í•™ìŠµ ì‹¤íŒ¨: {e}")
            continue
    
    # ì•™ìƒë¸” ê²°ê³¼ ì €ì¥
    if ensemble_results and not cleanup_flag:
        ensemble_dir = "outputs/ensemble"
        os.makedirs(ensemble_dir, exist_ok=True)
        
        with open(f"{ensemble_dir}/ensemble_results_fold_{fold}.json", 'w') as f:
            json.dump(ensemble_results, f, indent=2)
        
        print("\nğŸ‰ ì•™ìƒë¸” í•™ìŠµ ì™„ë£Œ!")
        print("ğŸ“Š ì•™ìƒë¸” ê²°ê³¼:")
        
        total_weight = 0
        for model_name, info in ensemble_results.items():
            print(f"  â€¢ {model_name}: Loss={info['val_loss']:.4f}, Weight={info['weight']*100}%")
            total_weight += info['weight']
        
        print(f"\nğŸ¯ ì´ ê°€ì¤‘ì¹˜: {total_weight*100}% (100%ê°€ ë˜ì–´ì•¼ í•¨)")
    else:
        print("\nğŸ›‘ ì•™ìƒë¸” í•™ìŠµì´ ì¤‘ë‹¨ë˜ì—ˆê±°ë‚˜ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

def main():
    parser = argparse.ArgumentParser(description='Train Ensemble Car Classification Models - User Recommended (Stable)')
    parser.add_argument('--config', type=str, default='config/config.yaml')
    parser.add_argument('--fold', type=int, default=0)
    parser.add_argument('--all_folds', action='store_true')
    args = parser.parse_args()
    
    try:
        if args.all_folds:
            print("ğŸš€ ëª¨ë“  Foldì— ëŒ€í•´ ì•™ìƒë¸” í•™ìŠµ ì‹œì‘!")
            for fold in range(5):
                if cleanup_flag:
                    break
                print(f"\n{'='*20} FOLD {fold} {'='*20}")
                train_ensemble(args.config, fold)
        else:
            train_ensemble(args.config, args.fold)
    except KeyboardInterrupt:
        print("\nğŸ›‘ í”„ë¡œê·¸ë¨ì´ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
    finally:
        print("\nğŸ§¹ ìµœì¢… ì •ë¦¬ ì¤‘...")
        cleanup_resources()
        print("âœ… í”„ë¡œê·¸ë¨ ì¢…ë£Œ")

if __name__ == "__main__":
    main() 