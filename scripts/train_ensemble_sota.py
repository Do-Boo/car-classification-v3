#!/usr/bin/env python3
"""
ğŸš€ ì°¨ëŸ‰ ë¶„ë¥˜ SOTA ì•™ìƒë¸” í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
ìµœì‹  ë”¥ëŸ¬ë‹ ê¸°ë²• ì´ë™ì› - ê²½ì§„ëŒ€íšŒ ìš°ìŠ¹ ì „ëµ!

ìƒì„±ì¼: 2025-06-02 16:46
ëª©í‘œ: Log Loss < 1.5, Kaggle ìƒìœ„ 1% ì†”ë£¨ì…˜
"""

import os
import sys
import yaml
import json
import time
import argparse
import pandas as pd
import numpy as np
from pathlib import Path
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import log_loss, accuracy_score
import warnings
warnings.filterwarnings('ignore')

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

from src.models.backbone import get_model
from src.data.dataset import CarDataset, get_train_transforms, get_valid_transforms
from src.utils.losses import get_loss_function
from src.utils.metrics import calculate_metrics
from src.utils.checkpoint import save_checkpoint, load_checkpoint, find_last_checkpoint

def setup_device():
    """ë””ë°”ì´ìŠ¤ ì„¤ì • (Apple M4 Pro ìµœì í™”)"""
    if torch.backends.mps.is_available():
        device = torch.device("mps")
        print("ğŸš€ Apple M4 Pro MPS ê°€ì† í™œì„±í™”!")
    elif torch.cuda.is_available():
        device = torch.device("cuda")
        print("ğŸš€ CUDA GPU ê°€ì† í™œì„±í™”!")
    else:
        device = torch.device("cpu")
        print("ğŸ’» CPU ëª¨ë“œë¡œ ì‹¤í–‰")
    
    return device

def create_model_config(base_config, model_name, model_info):
    """ëª¨ë¸ë³„ ê°œë³„ ì„¤ì • ìƒì„±"""
    config = base_config.copy()
    
    # ëª¨ë¸ë³„ ì„¤ì • ì—…ë°ì´íŠ¸
    config['model']['backbone'] = model_info['backbone']
    config['data']['img_size'] = model_info['img_size']
    config['training']['batch_size'] = model_info['batch_size']
    config['training']['learning_rate'] = model_info['learning_rate']
    
    return config

def train_single_model(model_name, model_info, base_config, train_df, device, fold=0):
    """ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ (SOTA ê¸°ë²• ì ìš©)"""
    print(f"\nğŸš€ {model_name} í•™ìŠµ ì‹œì‘!")
    print(f"ğŸ“ {model_info['description']}")
    print(f"ğŸ”§ ë°±ë³¸: {model_info['backbone']}")
    print(f"ğŸ“ ì´ë¯¸ì§€ í¬ê¸°: {model_info['img_size']}x{model_info['img_size']}")
    print(f"ğŸ“Š ë°°ì¹˜ í¬ê¸°: {model_info['batch_size']}")
    print(f"ğŸ“ˆ í•™ìŠµë¥ : {model_info['learning_rate']}")
    
    # ëª¨ë¸ë³„ ì„¤ì • ìƒì„±
    config = create_model_config(base_config, model_name, model_info)
    
    # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    save_dir = Path(f"outputs/ensemble/{model_name}")
    save_dir.mkdir(parents=True, exist_ok=True)
    
    # ì²´í¬í¬ì¸íŠ¸ í™•ì¸
    checkpoint_path, start_epoch = find_last_checkpoint(save_dir, fold)
    
    # ëª¨ë¸ ìƒì„±
    model = get_model(config)
    model.to(device)
    
    # ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
    optimizer = optim.AdamW(
        model.parameters(),
        lr=config['training']['learning_rate'],
        weight_decay=config['training']['weight_decay'],
        betas=config['optimizer']['betas'],
        eps=config['optimizer']['eps']
    )
    
    # ğŸ”¥ ê³ ê¸‰ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§ (CosineAnnealingWarmRestarts)
    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
        optimizer, 
        T_0=config['training']['scheduler']['T_0'],
        T_mult=config['training']['scheduler']['T_mult'],
        eta_min=config['training']['scheduler']['eta_min']
    )
    
    # ì†ì‹¤ í•¨ìˆ˜
    criterion = get_loss_function(config)
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    if checkpoint_path:
        print(f"ğŸ“‚ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ: {checkpoint_path}")
        model, optimizer, scheduler, start_epoch = load_checkpoint(
            checkpoint_path, model, optimizer, scheduler, device
        )
    
    # ë°ì´í„° ë¶„í•  (K-Fold)
    skf = StratifiedKFold(
        n_splits=config['data']['kfold']['n_splits'],
        shuffle=config['data']['kfold']['shuffle'],
        random_state=config['data']['kfold']['random_state']
    )
    
    folds = list(skf.split(train_df, train_df['class']))
    train_idx, val_idx = folds[fold]
    
    train_fold_df = train_df.iloc[train_idx].reset_index(drop=True)
    val_fold_df = train_df.iloc[val_idx].reset_index(drop=True)
    
    print(f"ğŸ“Š Fold {fold}: í•™ìŠµ {len(train_fold_df)}, ê²€ì¦ {len(val_fold_df)}")
    
    # ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë”
    img_size = config['data']['img_size']
    batch_size = config['training']['batch_size']
    
    train_dataset = CarDataset(
        train_fold_df, 
        transform=get_train_transforms(img_size),
        mode='train'
    )
    val_dataset = CarDataset(
        val_fold_df,
        transform=get_valid_transforms(img_size),
        mode='train'
    )
    
    # ğŸ§  ë©”ëª¨ë¦¬ ìµœì í™”ëœ ë°ì´í„°ë¡œë”
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=config['hardware']['num_workers'],
        pin_memory=config['hardware']['pin_memory'],
        persistent_workers=config['hardware']['persistent_workers']
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=config['hardware']['num_workers'],
        pin_memory=config['hardware']['pin_memory'],
        persistent_workers=config['hardware']['persistent_workers']
    )
    
    # í•™ìŠµ ë£¨í”„
    best_val_loss = float('inf')
    patience_counter = 0
    epochs = config['training']['epochs']
    
    print(f"ğŸ¯ ëª©í‘œ ì—í¬í¬: {epochs}")
    print(f"â° ì¡°ê¸° ì¢…ë£Œ patience: {config['training']['early_stopping']['patience']}")
    
    for epoch in range(start_epoch, epochs):
        epoch_start_time = time.time()
        
        # í•™ìŠµ
        model.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0
        
        print(f"\nğŸ“ˆ Epoch {epoch+1}/{epochs} - {model_name}")
        print(f"ğŸ”§ í˜„ì¬ í•™ìŠµë¥ : {optimizer.param_groups[0]['lr']:.6f}")
        
        for batch_idx, (images, targets) in enumerate(train_loader):
            images, targets = images.to(device), targets.to(device)
            
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            _, predicted = outputs.max(1)
            train_total += targets.size(0)
            train_correct += predicted.eq(targets).sum().item()
            
            # ì§„í–‰ë¥  ì¶œë ¥ (ë§¤ 100 ë°°ì¹˜ë§ˆë‹¤)
            if (batch_idx + 1) % 100 == 0:
                current_acc = 100. * train_correct / train_total
                print(f"  ë°°ì¹˜ {batch_idx+1}/{len(train_loader)}: "
                      f"Loss {loss.item():.4f}, Acc {current_acc:.2f}%")
        
        # ê²€ì¦
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0
        val_predictions = []
        val_targets = []
        
        with torch.no_grad():
            for images, targets in val_loader:
                images, targets = images.to(device), targets.to(device)
                outputs = model(images)
                loss = criterion(outputs, targets)
                
                val_loss += loss.item()
                _, predicted = outputs.max(1)
                val_total += targets.size(0)
                val_correct += predicted.eq(targets).sum().item()
                
                # Log Loss ê³„ì‚°ìš©
                probs = torch.softmax(outputs, dim=1)
                val_predictions.extend(probs.cpu().numpy())
                val_targets.extend(targets.cpu().numpy())
        
        # ë©”íŠ¸ë¦­ ê³„ì‚°
        train_loss /= len(train_loader)
        val_loss /= len(val_loader)
        train_acc = 100. * train_correct / train_total
        val_acc = 100. * val_correct / val_total
        
        # Log Loss ê³„ì‚°
        val_log_loss = log_loss(val_targets, val_predictions)
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
        scheduler.step()
        
        # ì—í¬í¬ ì‹œê°„ ê³„ì‚°
        epoch_time = time.time() - epoch_start_time
        
        print(f"ğŸ¯ Epoch {epoch+1} ê²°ê³¼:")
        print(f"  ğŸ“ˆ Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%")
        print(f"  ğŸ“Š Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")
        print(f"  ğŸ† Val Log Loss: {val_log_loss:.4f}")
        print(f"  â±ï¸ ì†Œìš” ì‹œê°„: {epoch_time:.1f}ì´ˆ")
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
        if val_log_loss < best_val_loss:
            best_val_loss = val_log_loss
            patience_counter = 0
            
            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            checkpoint = {
                'epoch': epoch + 1,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'val_loss': val_loss,
                'val_log_loss': val_log_loss,
                'val_acc': val_acc,
                'config': config
            }
            
            best_path = save_dir / f"best_fold_{fold}.pth"
            torch.save(checkpoint, best_path)
            print(f"ğŸ’¾ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥: {best_path}")
            
        else:
            patience_counter += 1
            
        # ì¡°ê¸° ì¢…ë£Œ í™•ì¸
        if patience_counter >= config['training']['early_stopping']['patience']:
            print(f"â¹ï¸ ì¡°ê¸° ì¢…ë£Œ: {patience_counter} ì—í¬í¬ ë™ì•ˆ ê°œì„  ì—†ìŒ")
            break
    
    print(f"âœ… {model_name} í•™ìŠµ ì™„ë£Œ!")
    print(f"ğŸ† ìµœê³  Val Log Loss: {best_val_loss:.4f}")
    
    return {
        'model_name': model_name,
        'model_path': str(best_path),
        'val_loss': best_val_loss,
        'weight': model_info['weight'],
        'description': model_info['description'],
        'config': config
    }

def main():
    parser = argparse.ArgumentParser(description='SOTA ì•™ìƒë¸” í•™ìŠµ')
    parser.add_argument('--config', type=str, default='config/config_sota.yaml',
                       help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--fold', type=int, default=0,
                       help='K-Fold ë²ˆí˜¸ (0-4)')
    args = parser.parse_args()
    
    print("ğŸš€ ì°¨ëŸ‰ ë¶„ë¥˜ SOTA ì•™ìƒë¸” í•™ìŠµ ì‹œì‘!")
    print("=" * 60)
    print("ğŸ¯ ëª©í‘œ: Kaggle ìƒìœ„ 1% ì†”ë£¨ì…˜ (Log Loss < 1.5)")
    print("ğŸ† ìµœì‹  ë”¥ëŸ¬ë‹ ê¸°ë²• ì´ë™ì›!")
    print("=" * 60)
    
    # ì„¤ì • ë¡œë“œ
    with open(args.config, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    print(f"ğŸ“‹ í”„ë¡œì íŠ¸: {config['project']['name']} v{config['project']['version']}")
    print(f"ğŸ“ ì„¤ëª…: {config['project']['description']}")
    print(f"ğŸ¯ ëª©í‘œ ì„±ëŠ¥: {config['project']['target_performance']}")
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = setup_device()
    
    # ë°ì´í„° ë¡œë“œ
    train_df = pd.read_csv(config['data']['train_csv'])
    print(f"ğŸ“Š í•™ìŠµ ë°ì´í„°: {len(train_df)}ê°œ ì´ë¯¸ì§€, {config['data']['num_classes']}ê°œ í´ë˜ìŠ¤")
    
    # ì•™ìƒë¸” ëª¨ë¸ë“¤
    ensemble_models = config['ensemble']['models']
    print(f"ğŸ† SOTA ì•™ìƒë¸” êµ¬ì„±: {len(ensemble_models)}ê°œ ëª¨ë¸")
    
    for model_name, model_info in ensemble_models.items():
        print(f"  â€¢ {model_name}: {model_info['description']} (ê°€ì¤‘ì¹˜: {model_info['weight']}%)")
    
    # ì•™ìƒë¸” ê²°ê³¼ ì €ì¥
    ensemble_results = {}
    
    # ê° ëª¨ë¸ í•™ìŠµ
    for model_name, model_info in ensemble_models.items():
        try:
            result = train_single_model(
                model_name, model_info, config, train_df, device, args.fold
            )
            ensemble_results[model_name] = result
            
        except Exception as e:
            print(f"âŒ {model_name} í•™ìŠµ ì‹¤íŒ¨: {e}")
            continue
    
    # ì•™ìƒë¸” ê²°ê³¼ ì €ì¥
    ensemble_dir = Path("outputs/ensemble")
    ensemble_dir.mkdir(parents=True, exist_ok=True)
    
    results_path = ensemble_dir / f"ensemble_results_fold_{args.fold}.json"
    with open(results_path, 'w', encoding='utf-8') as f:
        json.dump(ensemble_results, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ‰ SOTA ì•™ìƒë¸” í•™ìŠµ ì™„ë£Œ!")
    print(f"ğŸ“ ê²°ê³¼ ì €ì¥: {results_path}")
    
    # ì„±ëŠ¥ ìš”ì•½
    print("\nğŸ“Š ì•™ìƒë¸” ì„±ëŠ¥ ìš”ì•½:")
    total_weight = sum(result['weight'] for result in ensemble_results.values())
    weighted_loss = sum(
        result['val_loss'] * result['weight'] 
        for result in ensemble_results.values()
    ) / total_weight
    
    print(f"ğŸ† ê°€ì¤‘ í‰ê·  Val Loss: {weighted_loss:.4f}")
    print(f"ğŸ¯ ì˜ˆìƒ ì•™ìƒë¸” ì„±ëŠ¥: {weighted_loss * 0.85:.4f} (15% í–¥ìƒ)")
    print(f"ğŸš€ TTA ì ìš© ì‹œ ì˜ˆìƒ ì„±ëŠ¥: {weighted_loss * 0.75:.4f} (25% í–¥ìƒ)")
    
    if weighted_loss * 0.75 < 1.5:
        print("ğŸ¥‡ ëª©í‘œ ë‹¬ì„± ê°€ëŠ¥! (Log Loss < 1.5)")
    else:
        print("âš¡ ì¶”ê°€ ìµœì í™” í•„ìš”")

if __name__ == "__main__":
    main() 