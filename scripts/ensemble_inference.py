#!/usr/bin/env python3
"""
ğŸ† ì°¨ëŸ‰ ë¶„ë¥˜ ì•™ìƒë¸” ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ - ì‚¬ìš©ì ì¶”ì²œ 5ê°œ ëª¨ë¸ êµ¬ì„±
"""

import os
import sys
import yaml
import json
import argparse
import pandas as pd
import numpy as np
from pathlib import Path
import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader
from tqdm import tqdm

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

from src.models.backbone import get_model
from src.data.dataset import CarDataset, get_valid_transforms

def load_ensemble_models(ensemble_results_path, device):
    """ì‚¬ìš©ì ì¶”ì²œ ì•™ìƒë¸” ëª¨ë¸ë“¤ ë¡œë“œ"""
    with open(ensemble_results_path, 'r') as f:
        ensemble_results = json.load(f)
    
    models = {}
    
    print("ğŸ”„ ì•™ìƒë¸” ëª¨ë¸ ë¡œë“œ ì¤‘...")
    for model_name, info in ensemble_results.items():
        model_path = info['model_path']
        weight = info['weight']
        description = info.get('description', 'No description')
        
        if not os.path.exists(model_path):
            print(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
            continue
        
        try:
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
            checkpoint = torch.load(model_path, map_location=device)
            config = checkpoint['config']
            
            # ëª¨ë¸ ìƒì„± ë° ê°€ì¤‘ì¹˜ ë¡œë“œ
            model = get_model(config)
            model.load_state_dict(checkpoint['model_state_dict'])
            model.to(device)
            model.eval()
            
            models[model_name] = {
                'model': model,
                'weight': weight,
                'config': config,
                'val_loss': info['val_loss'],
                'description': description
            }
            
            print(f"âœ… {model_name}: {description}")
            print(f"   Weight: {weight*100}%, Val Loss: {info['val_loss']:.4f}")
            
        except Exception as e:
            print(f"âŒ {model_name} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            continue
    
    return models

def create_test_dataloader(test_df, img_size, batch_size=32):
    """í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œë” ìƒì„± (ëª¨ë¸ë³„ ì´ë¯¸ì§€ í¬ê¸° ëŒ€ì‘)"""
    test_transform = get_valid_transforms(img_size)
    test_dataset = CarDataset(test_df, transform=test_transform, mode='test')
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=8,
        shuffle=False,
        num_workers=0,
        pin_memory=False
    )
    
    return test_loader

def predict_single_model_with_tta(model, dataloader, device, model_name, tta_steps=5, num_classes=393):
    """TTAë¥¼ ì ìš©í•œ ë‹¨ì¼ ëª¨ë¸ ì˜ˆì¸¡"""
    model.eval()
    all_predictions = []
    
    print(f"ğŸ”„ {model_name} TTA ì˜ˆì¸¡ ì¤‘ (TTA steps: {tta_steps})")
    
    with torch.no_grad():
        for batch in tqdm(dataloader, desc=f"TTA Predicting {model_name}"):
            images = batch[0].to(device)
            batch_size = images.size(0)
            
            # TTA ì˜ˆì¸¡ë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
            tta_predictions = []
            
            for tta_step in range(tta_steps):
                # ì›ë³¸ ì´ë¯¸ì§€ (ì²« ë²ˆì§¸ ìŠ¤í…)
                if tta_step == 0:
                    augmented_images = images
                else:
                    # TTA ë³€í™˜ ì ìš©
                    augmented_images = apply_tta_transform(images, tta_step)
                
                outputs = model(augmented_images)
                batch_pred = F.softmax(outputs, dim=1)
                tta_predictions.append(batch_pred.cpu().numpy())
            
            # TTA ì˜ˆì¸¡ë“¤ì˜ í‰ê· 
            tta_avg = np.mean(tta_predictions, axis=0)
            all_predictions.append(tta_avg)
    
    return np.vstack(all_predictions)

def apply_tta_transform(images, tta_step):
    """TTA ë³€í™˜ ì ìš©"""
    if tta_step == 1:
        # ìˆ˜í‰ ë’¤ì§‘ê¸°
        return torch.flip(images, dims=[3])
    elif tta_step == 2:
        # ìˆ˜ì§ ë’¤ì§‘ê¸°
        return torch.flip(images, dims=[2])
    elif tta_step == 3:
        # ìˆ˜í‰ + ìˆ˜ì§ ë’¤ì§‘ê¸°
        return torch.flip(images, dims=[2, 3])
    elif tta_step == 4:
        # 90ë„ íšŒì „ (ì‹œê³„ë°©í–¥)
        return torch.rot90(images, k=1, dims=[2, 3])
    else:
        return images

def predict_single_model(model, dataloader, device, model_name):
    """ë‹¨ì¼ ëª¨ë¸ ì˜ˆì¸¡ (TTA ì—†ìŒ - í˜¸í™˜ì„± ìœ ì§€)"""
    return predict_single_model_with_tta(model, dataloader, device, model_name, tta_steps=1)

def ensemble_predict(models, test_df, device, use_tta=True, tta_steps=5):
    """ì‚¬ìš©ì ì¶”ì²œ 7ê°œ ëª¨ë¸ ì•™ìƒë¸” ì˜ˆì¸¡ (TTA ì ìš©)"""
    print("ğŸš€ ì‚¬ìš©ì ì¶”ì²œ 7ê°œ ëª¨ë¸ ì•™ìƒë¸” ì˜ˆì¸¡ ì‹œì‘!")
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìˆ˜: {len(test_df)}")
    print(f"ğŸ”„ TTA í™œì„±í™”: {use_tta}, TTA Steps: {tta_steps if use_tta else 1}")
    
    all_model_predictions = []
    weights = []
    
    for model_name, model_info in models.items():
        print(f"\nğŸ“Š {model_name} ì˜ˆì¸¡ ì¤‘...")
        print(f"ğŸ“ {model_info['description']}")
        
        model = model_info['model']
        weight = model_info['weight']
        config = model_info['config']
        
        # í•´ë‹¹ ëª¨ë¸ì˜ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë°ì´í„°ë¡œë” ìƒì„±
        img_size = config['data']['img_size']
        print(f"ğŸ”§ ì´ë¯¸ì§€ í¬ê¸°: {img_size}x{img_size}")
        
        test_loader = create_test_dataloader(test_df, img_size, batch_size=16)  # ë°°ì¹˜ í¬ê¸° ê°ì†Œ (TTAë¡œ ì¸í•œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€)
        
        # TTA ì ìš© ì˜ˆì¸¡ ìˆ˜í–‰
        if use_tta:
            predictions = predict_single_model_with_tta(model, test_loader, device, model_name, tta_steps)
        else:
            predictions = predict_single_model(model, test_loader, device, model_name)
        
        all_model_predictions.append(predictions)
        weights.append(weight)
        
        print(f"âœ… {model_name} ì˜ˆì¸¡ ì™„ë£Œ: {predictions.shape}")
        print(f"ğŸ¯ ê°€ì¤‘ì¹˜: {weight*100}%")
    
    # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì•™ìƒë¸”
    print("\nğŸ”„ ì•™ìƒë¸” ê²°í•© ì¤‘...")
    weights = np.array(weights)
    weights = weights / weights.sum()  # ì •ê·œí™”
    
    print("ğŸ“Š ìµœì¢… ê°€ì¤‘ì¹˜:")
    for i, (model_name, weight) in enumerate(zip(models.keys(), weights)):
        print(f"  â€¢ {model_name}: {weight*100:.1f}%")
    
    ensemble_predictions = np.zeros_like(all_model_predictions[0])
    for pred, weight in zip(all_model_predictions, weights):
        ensemble_predictions += pred * weight
    
    # ìµœì¢… ì˜ˆì¸¡ í´ë˜ìŠ¤
    ensemble_classes = np.argmax(ensemble_predictions, axis=1)
    
    print(f"\nğŸ‰ ì•™ìƒë¸” ì˜ˆì¸¡ ì™„ë£Œ: {ensemble_predictions.shape}")
    if use_tta:
        print(f"ğŸš€ TTA {tta_steps}ë°° ì ìš©ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ!")
    
    return ensemble_predictions, ensemble_classes

def create_submission(test_df, predictions, class_info, output_path):
    """ì œì¶œ íŒŒì¼ ìƒì„±"""
    # í´ë˜ìŠ¤ ì¸ë±ìŠ¤ë¥¼ í´ë˜ìŠ¤ëª…ìœ¼ë¡œ ë³€í™˜
    label_to_class = class_info['label_to_class']
    predicted_classes = [label_to_class[str(pred)] for pred in predictions]
    
    # ì œì¶œ DataFrame ìƒì„±
    submission_df = pd.DataFrame({
        'img_path': test_df['img_path'].apply(lambda x: os.path.basename(x)),
        'class': predicted_classes
    })
    
    # CSV ì €ì¥
    submission_df.to_csv(output_path, index=False)
    print(f"ğŸ’¾ ì œì¶œ íŒŒì¼ ì €ì¥: {output_path}")
    
    # ì˜ˆì¸¡ ë¶„í¬ ì¶œë ¥
    class_counts = submission_df['class'].value_counts()
    print(f"\nğŸ“Š ì˜ˆì¸¡ í´ë˜ìŠ¤ ë¶„í¬ (ìƒìœ„ 10ê°œ):")
    print(class_counts.head(10))
    
    print(f"\nğŸ“ˆ ì´ ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ìˆ˜: {len(class_counts)}/396")

def main():
    parser = argparse.ArgumentParser(description='Ensemble Inference for Car Classification - User Recommended 7 Models with TTA')
    parser.add_argument('--ensemble_results', type=str, required=True)
    parser.add_argument('--test_csv', type=str, default='data/test.csv')
    parser.add_argument('--class_info', type=str, default='outputs/data/class_info.json')
    parser.add_argument('--output', type=str, default='outputs/user_ensemble_submission_tta.csv')
    parser.add_argument('--fold', type=int, default=0)
    parser.add_argument('--use_tta', action='store_true', default=True, help='Use Test Time Augmentation')
    parser.add_argument('--tta_steps', type=int, default=5, help='Number of TTA steps')
    args = parser.parse_args()
    
    print("ğŸ† ì‚¬ìš©ì ì¶”ì²œ 7ê°œ ëª¨ë¸ ì•™ìƒë¸” ì¶”ë¡  ì‹œì‘!")
    print("ğŸ¯ ëª¨ë¸ êµ¬ì„±: EfficientNetV2-XL + ConvNeXt-XL + Swin-V2 + EfficientNet-B7 + ConvNeXt-L + ResNet200D + ViT-L")
    print(f"ğŸš€ TTA í™œì„±í™”: {args.use_tta}, TTA Steps: {args.tta_steps}")
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    if torch.backends.mps.is_available():
        device = torch.device('mps')
        print("âœ… Apple Silicon GPU (MPS) ì‚¬ìš©")
    else:
        device = torch.device('cpu')
        print("âš ï¸ CPU ì‚¬ìš©")
    
    # ì•™ìƒë¸” ê²°ê³¼ íŒŒì¼ ê²½ë¡œ ì„¤ì •
    if not os.path.exists(args.ensemble_results):
        ensemble_results_path = f"outputs/ensemble/ensemble_results_fold_{args.fold}.json"
        if os.path.exists(ensemble_results_path):
            args.ensemble_results = ensemble_results_path
        else:
            print(f"âŒ ì•™ìƒë¸” ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.ensemble_results}")
            return
    
    # ë°ì´í„° ë¡œë“œ
    print("\nğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘...")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    if os.path.exists(args.test_csv):
        test_df = pd.read_csv(args.test_csv)
    else:
        # í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜ì§‘
        test_dir = "data/test"
        if os.path.exists(test_dir):
            test_files = []
            for file in os.listdir(test_dir):
                if file.lower().endswith(('.jpg', '.jpeg', '.png')):
                    test_files.append(os.path.join(test_dir, file))
            test_df = pd.DataFrame({'img_path': test_files})
        else:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.test_csv}")
            return
    
    # í´ë˜ìŠ¤ ì •ë³´
    with open(args.class_info, 'r') as f:
        class_info = json.load(f)
    
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìˆ˜: {len(test_df)}")
    print(f"ğŸ“Š í´ë˜ìŠ¤ ìˆ˜: {class_info['num_classes']}")
    
    # ì•™ìƒë¸” ëª¨ë¸ ë¡œë“œ
    print(f"\nğŸ”„ ì•™ìƒë¸” ëª¨ë¸ ë¡œë“œ ì¤‘...")
    models = load_ensemble_models(args.ensemble_results, device)
    
    if not models:
        print("âŒ ë¡œë“œëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"\nâœ… {len(models)}ê°œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    # ì•™ìƒë¸” ì˜ˆì¸¡ (TTA ì ìš©)
    ensemble_proba, ensemble_pred = ensemble_predict(
        models, test_df, device, 
        use_tta=args.use_tta, 
        tta_steps=args.tta_steps
    )
    
    # ì œì¶œ íŒŒì¼ ìƒì„±
    print("\nğŸ“ ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...")
    os.makedirs(os.path.dirname(args.output), exist_ok=True)
    create_submission(test_df, ensemble_pred, class_info, args.output)
    
    print("\nğŸ‰ ì‚¬ìš©ì ì¶”ì²œ 7ê°œ ëª¨ë¸ ì•™ìƒë¸” ì¶”ë¡  ì™„ë£Œ!")
    print("ğŸ† EfficientNetV2-XL + ConvNeXt-XL + Swin-V2 + EfficientNet-B7 + ConvNeXt-L + ResNet200D + ViT-L = ìµœê°• ì•™ìƒë¸”!")
    if args.use_tta:
        print(f"ğŸš€ TTA {args.tta_steps}ë°° ì ìš©ìœ¼ë¡œ ì„±ëŠ¥ ëŒ€í­ í–¥ìƒ!")

if __name__ == "__main__":
    main() 