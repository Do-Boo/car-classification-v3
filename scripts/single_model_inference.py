#!/usr/bin/env python3
"""
ë‹¨ì¼ ëª¨ë¸ ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ - ê¸°ì¡´ í•™ìŠµëœ ëª¨ë¸ ì„±ëŠ¥ í™•ì¸
"""

import os
import sys
import yaml
import json
import pandas as pd
import numpy as np
from pathlib import Path
import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader
from tqdm import tqdm

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

from src.models.backbone import get_model
from src.data.dataset import CarDataset, get_valid_transforms

def load_model_and_config(model_path, device):
    """ëª¨ë¸ê³¼ ì„¤ì • ë¡œë“œ"""
    print(f"ğŸ”„ ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}")
    
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    checkpoint = torch.load(model_path, map_location=device)
    config = checkpoint['config']
    
    # ëª¨ë¸ ìƒì„± ë° ê°€ì¤‘ì¹˜ ë¡œë“œ
    model = get_model(config)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    model.eval()
    
    print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    print(f"ğŸ“Š ëª¨ë¸ ì •ë³´:")
    print(f"   - ë°±ë³¸: {config['model']['backbone']}")
    print(f"   - ì´ë¯¸ì§€ í¬ê¸°: {config['data']['img_size']}")
    print(f"   - í´ë˜ìŠ¤ ìˆ˜: {config['data']['num_classes']}")
    
    if 'val_loss' in checkpoint:
        print(f"   - ê²€ì¦ Loss: {checkpoint['val_loss']:.4f}")
    if 'val_log_loss' in checkpoint:
        print(f"   - ê²€ì¦ Log Loss: {checkpoint['val_log_loss']:.4f}")
    
    return model, config

def create_test_dataloader(test_df, config):
    """í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œë” ìƒì„±"""
    img_size = config['data']['img_size']
    
    # ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì •
    test_df = test_df.copy()
    test_df['img_path'] = test_df['img_path'].apply(lambda x: x.replace('./test/', 'data/test/'))
    
    test_transform = get_valid_transforms(img_size)
    test_dataset = CarDataset(test_df, transform=test_transform, mode='test')
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=16,
        shuffle=False,
        num_workers=0,
        pin_memory=False
    )
    
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_dataset)}ê°œ ì´ë¯¸ì§€")
    print(f"ğŸ”§ ë°°ì¹˜ í¬ê¸°: 16, ì´ë¯¸ì§€ í¬ê¸°: {img_size}x{img_size}")
    
    return test_loader

def predict_model(model, dataloader, device):
    """ëª¨ë¸ ì˜ˆì¸¡ ì‹¤í–‰"""
    model.eval()
    all_predictions = []
    all_paths = []
    
    print("ğŸ”„ ì˜ˆì¸¡ ì‹¤í–‰ ì¤‘...")
    
    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Predicting"):
            images, paths = batch
            images = images.to(device)
            
            outputs = model(images)
            predictions = F.softmax(outputs, dim=1)
            
            all_predictions.append(predictions.cpu().numpy())
            all_paths.extend(paths)
    
    predictions = np.vstack(all_predictions)
    
    print(f"âœ… ì˜ˆì¸¡ ì™„ë£Œ: {predictions.shape}")
    
    return predictions, all_paths

def create_submission(test_df, predictions, output_path):
    """ì œì¶œ íŒŒì¼ ìƒì„±"""
    print("ğŸ“ ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...")
    
    # sample_submission.csvì—ì„œ ì‹¤ì œ í´ë˜ìŠ¤ëª… ê°€ì ¸ì˜¤ê¸°
    sample_submission_path = "data/sample_submission.csv"
    class_names = None
    
    try:
        if os.path.exists(sample_submission_path):
            # í—¤ë”ë§Œ ì½ê¸°
            sample_df = pd.read_csv(sample_submission_path, nrows=0)  # í—¤ë”ë§Œ ì½ê¸°
            class_names = list(sample_df.columns[1:])  # ID ì»¬ëŸ¼ ì œì™¸
            print(f"âœ… sample_submission.csvì—ì„œ í´ë˜ìŠ¤ëª… ë¡œë“œ: {len(class_names)}ê°œ í´ë˜ìŠ¤")
            print(f"ğŸ” ì²« 5ê°œ í´ë˜ìŠ¤: {class_names[:5]}")
        else:
            print(f"âš ï¸ sample_submission.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {sample_submission_path}")
    except Exception as e:
        print(f"âš ï¸ sample_submission.csv ë¡œë“œ ì˜¤ë¥˜: {e}")
    
    # í´ë˜ìŠ¤ ì •ë³´ íŒŒì¼ì—ì„œ ë°±ì—…ìœ¼ë¡œ ì‹œë„
    if class_names is None:
        class_info_path = "outputs/data/class_info.json"
        try:
            if os.path.exists(class_info_path):
                with open(class_info_path, 'r') as f:
                    class_info = json.load(f)
                class_names = class_info['class_names']
                print(f"âœ… class_info.jsonì—ì„œ í´ë˜ìŠ¤ëª… ë¡œë“œ: {len(class_names)}ê°œ í´ë˜ìŠ¤")
        except Exception as e:
            print(f"âš ï¸ class_info.json ë¡œë“œ ì˜¤ë¥˜: {e}")
    
    # ì˜ˆì¸¡ ê²°ê³¼ì™€ í´ë˜ìŠ¤ëª… ìˆ˜ ë§ì¶”ê¸°
    if class_names is not None and len(class_names) != predictions.shape[1]:
        print(f"âš ï¸ í´ë˜ìŠ¤ ìˆ˜ ë¶ˆì¼ì¹˜: ëª¨ë¸={predictions.shape[1]}, sample_submission={len(class_names)}")
        
        if len(class_names) > predictions.shape[1]:
            # sample_submissionì— ë” ë§ì€ í´ë˜ìŠ¤ê°€ ìˆëŠ” ê²½ìš°, ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜ì— ë§ì¶° ì¡°ì •
            class_names = class_names[:predictions.shape[1]]
            print(f"âœ… í´ë˜ìŠ¤ëª…ì„ ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜ì— ë§ì¶° ì¡°ì •: {len(class_names)}ê°œ")
        else:
            # ëª¨ë¸ì´ ë” ë§ì€ í´ë˜ìŠ¤ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê²½ìš°, ë¶€ì¡±í•œ í´ë˜ìŠ¤ëª… ì¶”ê°€
            for i in range(len(class_names), predictions.shape[1]):
                class_names.append(f"class_{i}")
            print(f"âœ… ë¶€ì¡±í•œ í´ë˜ìŠ¤ëª… ì¶”ê°€: {len(class_names)}ê°œ")
    elif class_names is None:
        # ê¸°ë³¸ í´ë˜ìŠ¤ëª… ìƒì„± (ìµœí›„ ìˆ˜ë‹¨)
        class_names = [f"class_{i}" for i in range(predictions.shape[1])]
        print(f"âš ï¸ ê¸°ë³¸ í´ë˜ìŠ¤ëª… ì‚¬ìš©: {len(class_names)}ê°œ í´ë˜ìŠ¤")
    
    # ì œì¶œ DataFrame ìƒì„± (ì„±ëŠ¥ ìµœì í™”)
    print("ğŸ“Š DataFrame ìƒì„± ì¤‘...")
    
    # ID ì»¬ëŸ¼ê³¼ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í•œ ë²ˆì— ê²°í•©
    data_dict = {'ID': test_df['ID'].values}
    
    # í´ë˜ìŠ¤ë³„ í™•ë¥ ì„ ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€
    for i, class_name in enumerate(class_names):
        if i < predictions.shape[1]:
            data_dict[class_name] = predictions[:, i]
    
    # í•œ ë²ˆì— DataFrame ìƒì„±
    submission = pd.DataFrame(data_dict)
    
    # ì €ì¥
    submission.to_csv(output_path, index=False)
    
    print(f"âœ… ì œì¶œ íŒŒì¼ ì €ì¥: {output_path}")
    print(f"ğŸ“Š ì œì¶œ íŒŒì¼ shape: {submission.shape}")
    print(f"ğŸ” í™•ë¥  í•© ê²€ì¦: {submission.iloc[:, 1:].sum(axis=1).mean():.6f}")
    
    # ì˜ˆì¸¡ ë¶„í¬ í™•ì¸
    predicted_classes = np.argmax(predictions, axis=1)
    unique_classes, counts = np.unique(predicted_classes, return_counts=True)
    
    print(f"\nğŸ“ˆ ì˜ˆì¸¡ ë¶„í¬ (ìƒìœ„ 10ê°œ í´ë˜ìŠ¤):")
    sorted_indices = np.argsort(counts)[::-1][:10]
    for idx in sorted_indices:
        class_idx = unique_classes[idx]
        count = counts[idx]
        percentage = count / len(predicted_classes) * 100
        class_name = class_names[class_idx] if class_idx < len(class_names) else f"class_{class_idx}"
        print(f"  {class_name}: {count}ê°œ ({percentage:.1f}%)")
    
    # í—¤ë” í™•ì¸
    print(f"\nğŸ“‹ ì œì¶œ íŒŒì¼ í—¤ë” (ì²˜ìŒ 5ê°œ):")
    print(f"  {', '.join(submission.columns[:6])}")
    
    return submission

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("="*60)
    print("ğŸš— ì°¨ëŸ‰ ë¶„ë¥˜ ë‹¨ì¼ ëª¨ë¸ ì¶”ë¡ ")
    print("="*60)
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
    print(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {device}")
    
    # ëª¨ë¸ ê²½ë¡œ
    model_path = "outputs/ensemble/efficientnetv2_l/fold_0/best_model.pth"
    
    try:
        # 1. ëª¨ë¸ ë¡œë“œ
        model, config = load_model_and_config(model_path, device)
        
        # 2. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
        print(f"\nğŸ“‚ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì¤‘...")
        test_df = pd.read_csv("data/test.csv")
        print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìˆ˜: {len(test_df)}")
        
        # 3. ë°ì´í„°ë¡œë” ìƒì„±
        test_loader = create_test_dataloader(test_df, config)
        
        # 4. ì˜ˆì¸¡ ì‹¤í–‰
        print(f"\nğŸš€ ì˜ˆì¸¡ ì‹œì‘...")
        predictions, paths = predict_model(model, test_loader, device)
        
        # 5. ì œì¶œ íŒŒì¼ ìƒì„±
        output_path = "outputs/single_model_submission.csv"
        create_submission(test_df, predictions, output_path)
        
        print(f"\nğŸ‰ ì¶”ë¡  ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {output_path}")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 